Before oversampling: Counter({0.0: 22772, 10.0: 15114, 50.0: 15085, 90.0: 15054, 30.0: 14964, 70.0: 14771, 92.0: 7628, 100.0: 7624})
After oversampling: Counter({100.0: 22772, 92.0: 22772, 90.0: 22772, 10.0: 22772, 0.0: 22772, 70.0: 22772, 50.0: 22772, 30.0: 22772})
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 12, 64)            512       
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 6, 64)             28736     
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 3, 64)             0         
_________________________________________________________________
flatten (Flatten)            (None, 192)               0         
_________________________________________________________________
dense (Dense)                (None, 17)                3281      
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 144       
=================================================================
Total params: 32,673
Trainable params: 32,673
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
18218/18218 - 15s - loss: 1.4375 - accuracy: 0.4357 - val_loss: 1.3629 - val_accuracy: 0.4558

Epoch 00001: val_loss improved from inf to 1.36286, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 2/100
18218/18218 - 15s - loss: 1.3424 - accuracy: 0.4751 - val_loss: 1.3405 - val_accuracy: 0.4650

Epoch 00002: val_loss improved from 1.36286 to 1.34048, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 3/100
18218/18218 - 15s - loss: 1.3173 - accuracy: 0.4871 - val_loss: 1.3238 - val_accuracy: 0.4755

Epoch 00003: val_loss improved from 1.34048 to 1.32378, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 4/100
18218/18218 - 15s - loss: 1.3028 - accuracy: 0.4946 - val_loss: 1.3035 - val_accuracy: 0.4839

Epoch 00004: val_loss improved from 1.32378 to 1.30347, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 5/100
18218/18218 - 15s - loss: 1.2831 - accuracy: 0.5023 - val_loss: 1.3062 - val_accuracy: 0.4801

Epoch 00005: val_loss did not improve from 1.30347
Epoch 6/100
18218/18218 - 15s - loss: 1.2643 - accuracy: 0.5091 - val_loss: 1.2835 - val_accuracy: 0.4906

Epoch 00006: val_loss improved from 1.30347 to 1.28354, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 7/100
18218/18218 - 15s - loss: 1.2540 - accuracy: 0.5120 - val_loss: 1.2656 - val_accuracy: 0.5028

Epoch 00007: val_loss improved from 1.28354 to 1.26556, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 8/100
18218/18218 - 15s - loss: 1.2450 - accuracy: 0.5174 - val_loss: 1.2705 - val_accuracy: 0.4913

Epoch 00008: val_loss did not improve from 1.26556
Epoch 9/100
18218/18218 - 15s - loss: 1.2384 - accuracy: 0.5218 - val_loss: 1.2708 - val_accuracy: 0.5006

Epoch 00009: val_loss did not improve from 1.26556
Epoch 10/100
18218/18218 - 15s - loss: 1.2293 - accuracy: 0.5267 - val_loss: 1.2661 - val_accuracy: 0.5037

Epoch 00010: val_loss did not improve from 1.26556
Epoch 11/100
18218/18218 - 15s - loss: 1.2237 - accuracy: 0.5297 - val_loss: 1.2867 - val_accuracy: 0.4976

Epoch 00011: val_loss did not improve from 1.26556
Epoch 12/100
18218/18218 - 15s - loss: 1.2194 - accuracy: 0.5320 - val_loss: 1.2415 - val_accuracy: 0.5213

Epoch 00012: val_loss improved from 1.26556 to 1.24146, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 13/100
18218/18218 - 15s - loss: 1.2159 - accuracy: 0.5328 - val_loss: 1.2805 - val_accuracy: 0.4957

Epoch 00013: val_loss did not improve from 1.24146
Epoch 14/100
18218/18218 - 15s - loss: 1.2116 - accuracy: 0.5346 - val_loss: 1.2661 - val_accuracy: 0.5066

Epoch 00014: val_loss did not improve from 1.24146
Epoch 15/100
18218/18218 - 15s - loss: 1.2076 - accuracy: 0.5358 - val_loss: 1.2383 - val_accuracy: 0.5219

Epoch 00015: val_loss improved from 1.24146 to 1.23832, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 16/100
18218/18218 - 15s - loss: 1.2046 - accuracy: 0.5387 - val_loss: 1.2323 - val_accuracy: 0.5281

Epoch 00016: val_loss improved from 1.23832 to 1.23229, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 17/100
18218/18218 - 15s - loss: 1.2029 - accuracy: 0.5397 - val_loss: 1.2491 - val_accuracy: 0.5117

Epoch 00017: val_loss did not improve from 1.23229
Epoch 18/100
18218/18218 - 15s - loss: 1.1993 - accuracy: 0.5409 - val_loss: 1.2398 - val_accuracy: 0.5178

Epoch 00018: val_loss did not improve from 1.23229
Epoch 19/100
18218/18218 - 15s - loss: 1.1961 - accuracy: 0.5399 - val_loss: 1.2352 - val_accuracy: 0.5211

Epoch 00019: val_loss did not improve from 1.23229
Epoch 20/100
18218/18218 - 15s - loss: 1.1945 - accuracy: 0.5416 - val_loss: 1.2621 - val_accuracy: 0.5141

Epoch 00020: val_loss did not improve from 1.23229
Epoch 21/100
18218/18218 - 15s - loss: 1.1920 - accuracy: 0.5426 - val_loss: 1.2368 - val_accuracy: 0.5251

Epoch 00021: val_loss did not improve from 1.23229
Epoch 22/100
18218/18218 - 15s - loss: 1.1900 - accuracy: 0.5449 - val_loss: 1.2635 - val_accuracy: 0.5132

Epoch 00022: val_loss did not improve from 1.23229
Epoch 23/100
18218/18218 - 15s - loss: 1.1878 - accuracy: 0.5458 - val_loss: 1.2622 - val_accuracy: 0.5070

Epoch 00023: val_loss did not improve from 1.23229
Epoch 24/100
18218/18218 - 15s - loss: 1.1869 - accuracy: 0.5454 - val_loss: 1.2282 - val_accuracy: 0.5274

Epoch 00024: val_loss improved from 1.23229 to 1.22819, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 25/100
18218/18218 - 15s - loss: 1.1845 - accuracy: 0.5465 - val_loss: 1.2410 - val_accuracy: 0.5173

Epoch 00025: val_loss did not improve from 1.22819
Epoch 26/100
18218/18218 - 15s - loss: 1.1837 - accuracy: 0.5478 - val_loss: 1.2461 - val_accuracy: 0.5154

Epoch 00026: val_loss did not improve from 1.22819
Epoch 27/100
18218/18218 - 15s - loss: 1.1821 - accuracy: 0.5478 - val_loss: 1.2299 - val_accuracy: 0.5293

Epoch 00027: val_loss did not improve from 1.22819
Epoch 28/100
18218/18218 - 15s - loss: 1.1802 - accuracy: 0.5494 - val_loss: 1.2283 - val_accuracy: 0.5237

Epoch 00028: val_loss did not improve from 1.22819
Epoch 29/100
18218/18218 - 16s - loss: 1.1788 - accuracy: 0.5495 - val_loss: 1.2217 - val_accuracy: 0.5295

Epoch 00029: val_loss improved from 1.22819 to 1.22165, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 30/100
18218/18218 - 15s - loss: 1.1776 - accuracy: 0.5494 - val_loss: 1.2432 - val_accuracy: 0.5217

Epoch 00030: val_loss did not improve from 1.22165
Epoch 31/100
18218/18218 - 15s - loss: 1.1763 - accuracy: 0.5519 - val_loss: 1.2347 - val_accuracy: 0.5230

Epoch 00031: val_loss did not improve from 1.22165
Epoch 32/100
18218/18218 - 16s - loss: 1.1753 - accuracy: 0.5516 - val_loss: 1.2328 - val_accuracy: 0.5222

Epoch 00032: val_loss did not improve from 1.22165
Epoch 33/100
18218/18218 - 15s - loss: 1.1730 - accuracy: 0.5507 - val_loss: 1.2472 - val_accuracy: 0.5120

Epoch 00033: val_loss did not improve from 1.22165
Epoch 34/100
18218/18218 - 15s - loss: 1.1725 - accuracy: 0.5520 - val_loss: 1.2495 - val_accuracy: 0.5131

Epoch 00034: val_loss did not improve from 1.22165
Epoch 35/100
18218/18218 - 15s - loss: 1.1706 - accuracy: 0.5528 - val_loss: 1.2234 - val_accuracy: 0.5264

Epoch 00035: val_loss did not improve from 1.22165
Epoch 36/100
18218/18218 - 15s - loss: 1.1699 - accuracy: 0.5546 - val_loss: 1.2164 - val_accuracy: 0.5328

Epoch 00036: val_loss improved from 1.22165 to 1.21637, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 37/100
18218/18218 - 15s - loss: 1.1696 - accuracy: 0.5533 - val_loss: 1.2274 - val_accuracy: 0.5297

Epoch 00037: val_loss did not improve from 1.21637
Epoch 38/100
18218/18218 - 15s - loss: 1.1670 - accuracy: 0.5552 - val_loss: 1.2300 - val_accuracy: 0.5249

Epoch 00038: val_loss did not improve from 1.21637
Epoch 39/100
18218/18218 - 16s - loss: 1.1660 - accuracy: 0.5535 - val_loss: 1.2272 - val_accuracy: 0.5268

Epoch 00039: val_loss did not improve from 1.21637
Epoch 40/100
18218/18218 - 15s - loss: 1.1655 - accuracy: 0.5557 - val_loss: 1.2280 - val_accuracy: 0.5276

Epoch 00040: val_loss did not improve from 1.21637
Epoch 41/100
18218/18218 - 16s - loss: 1.1645 - accuracy: 0.5556 - val_loss: 1.2316 - val_accuracy: 0.5331

Epoch 00041: val_loss did not improve from 1.21637
Epoch 42/100
18218/18218 - 15s - loss: 1.1638 - accuracy: 0.5561 - val_loss: 1.2447 - val_accuracy: 0.5160

Epoch 00042: val_loss did not improve from 1.21637
Epoch 43/100
18218/18218 - 15s - loss: 1.1638 - accuracy: 0.5541 - val_loss: 1.2240 - val_accuracy: 0.5329

Epoch 00043: val_loss did not improve from 1.21637
Epoch 44/100
18218/18218 - 15s - loss: 1.1617 - accuracy: 0.5561 - val_loss: 1.2423 - val_accuracy: 0.5208

Epoch 00044: val_loss did not improve from 1.21637
Epoch 45/100
18218/18218 - 15s - loss: 1.1596 - accuracy: 0.5567 - val_loss: 1.2348 - val_accuracy: 0.5245

Epoch 00045: val_loss did not improve from 1.21637
Epoch 46/100
18218/18218 - 15s - loss: 1.1605 - accuracy: 0.5556 - val_loss: 1.2436 - val_accuracy: 0.5238

Epoch 00046: val_loss did not improve from 1.21637
Epoch 47/100
18218/18218 - 15s - loss: 1.1599 - accuracy: 0.5566 - val_loss: 1.2410 - val_accuracy: 0.5239

Epoch 00047: val_loss did not improve from 1.21637
Epoch 48/100
18218/18218 - 15s - loss: 1.1584 - accuracy: 0.5578 - val_loss: 1.2380 - val_accuracy: 0.5193

Epoch 00048: val_loss did not improve from 1.21637
Epoch 49/100
18218/18218 - 15s - loss: 1.1583 - accuracy: 0.5582 - val_loss: 1.2321 - val_accuracy: 0.5302

Epoch 00049: val_loss did not improve from 1.21637
Epoch 50/100
18218/18218 - 15s - loss: 1.1571 - accuracy: 0.5573 - val_loss: 1.2286 - val_accuracy: 0.5278

Epoch 00050: val_loss did not improve from 1.21637
Epoch 51/100
18218/18218 - 15s - loss: 1.1565 - accuracy: 0.5581 - val_loss: 1.2235 - val_accuracy: 0.5296

Epoch 00051: val_loss did not improve from 1.21637
Epoch 52/100
18218/18218 - 15s - loss: 1.1547 - accuracy: 0.5587 - val_loss: 1.2493 - val_accuracy: 0.5172

Epoch 00052: val_loss did not improve from 1.21637
Epoch 53/100
18218/18218 - 15s - loss: 1.1546 - accuracy: 0.5592 - val_loss: 1.2326 - val_accuracy: 0.5261

Epoch 00053: val_loss did not improve from 1.21637
Epoch 54/100
18218/18218 - 15s - loss: 1.1526 - accuracy: 0.5609 - val_loss: 1.2354 - val_accuracy: 0.5223

Epoch 00054: val_loss did not improve from 1.21637
Epoch 55/100
18218/18218 - 15s - loss: 1.1531 - accuracy: 0.5595 - val_loss: 1.2428 - val_accuracy: 0.5336

Epoch 00055: val_loss did not improve from 1.21637
Epoch 56/100
18218/18218 - 15s - loss: 1.1511 - accuracy: 0.5601 - val_loss: 1.2424 - val_accuracy: 0.5161

Epoch 00056: val_loss did not improve from 1.21637
Epoch 57/100
18218/18218 - 15s - loss: 1.1503 - accuracy: 0.5615 - val_loss: 1.2349 - val_accuracy: 0.5237

Epoch 00057: val_loss did not improve from 1.21637
Epoch 58/100
18218/18218 - 15s - loss: 1.1506 - accuracy: 0.5605 - val_loss: 1.2301 - val_accuracy: 0.5226

Epoch 00058: val_loss did not improve from 1.21637
Epoch 59/100
18218/18218 - 15s - loss: 1.1500 - accuracy: 0.5605 - val_loss: 1.2189 - val_accuracy: 0.5300

Epoch 00059: val_loss did not improve from 1.21637
Epoch 60/100
18218/18218 - 15s - loss: 1.1485 - accuracy: 0.5614 - val_loss: 1.2220 - val_accuracy: 0.5325

Epoch 00060: val_loss did not improve from 1.21637
Epoch 61/100
18218/18218 - 15s - loss: 1.1484 - accuracy: 0.5614 - val_loss: 1.2277 - val_accuracy: 0.5348

Epoch 00061: val_loss did not improve from 1.21637
Epoch 62/100
18218/18218 - 15s - loss: 1.1482 - accuracy: 0.5614 - val_loss: 1.2268 - val_accuracy: 0.5342

Epoch 00062: val_loss did not improve from 1.21637
Epoch 63/100
18218/18218 - 15s - loss: 1.1475 - accuracy: 0.5615 - val_loss: 1.2214 - val_accuracy: 0.5330

Epoch 00063: val_loss did not improve from 1.21637
Epoch 64/100
18218/18218 - 15s - loss: 1.1465 - accuracy: 0.5630 - val_loss: 1.2362 - val_accuracy: 0.5292

Epoch 00064: val_loss did not improve from 1.21637
Epoch 65/100
18218/18218 - 15s - loss: 1.1461 - accuracy: 0.5635 - val_loss: 1.2324 - val_accuracy: 0.5295

Epoch 00065: val_loss did not improve from 1.21637
Epoch 66/100
18218/18218 - 15s - loss: 1.1463 - accuracy: 0.5625 - val_loss: 1.2266 - val_accuracy: 0.5348

Epoch 00066: val_loss did not improve from 1.21637
Epoch 67/100
18218/18218 - 15s - loss: 1.1445 - accuracy: 0.5625 - val_loss: 1.2345 - val_accuracy: 0.5248

Epoch 00067: val_loss did not improve from 1.21637
Epoch 68/100
18218/18218 - 15s - loss: 1.1445 - accuracy: 0.5622 - val_loss: 1.2403 - val_accuracy: 0.5255

Epoch 00068: val_loss did not improve from 1.21637
Epoch 69/100
18218/18218 - 15s - loss: 1.1437 - accuracy: 0.5636 - val_loss: 1.2190 - val_accuracy: 0.5398

Epoch 00069: val_loss did not improve from 1.21637
Epoch 70/100
18218/18218 - 15s - loss: 1.1440 - accuracy: 0.5624 - val_loss: 1.2370 - val_accuracy: 0.5299

Epoch 00070: val_loss did not improve from 1.21637
Epoch 71/100
18218/18218 - 15s - loss: 1.1430 - accuracy: 0.5633 - val_loss: 1.2255 - val_accuracy: 0.5279

Epoch 00071: val_loss did not improve from 1.21637
Epoch 72/100
18218/18218 - 15s - loss: 1.1431 - accuracy: 0.5631 - val_loss: 1.2203 - val_accuracy: 0.5308

Epoch 00072: val_loss did not improve from 1.21637
Epoch 73/100
18218/18218 - 15s - loss: 1.1427 - accuracy: 0.5637 - val_loss: 1.2201 - val_accuracy: 0.5378

Epoch 00073: val_loss did not improve from 1.21637
Epoch 74/100
18218/18218 - 15s - loss: 1.1426 - accuracy: 0.5648 - val_loss: 1.2420 - val_accuracy: 0.5231

Epoch 00074: val_loss did not improve from 1.21637
Epoch 75/100
18218/18218 - 15s - loss: 1.1431 - accuracy: 0.5656 - val_loss: 1.2403 - val_accuracy: 0.5290

Epoch 00075: val_loss did not improve from 1.21637
Epoch 76/100
18218/18218 - 15s - loss: 1.1410 - accuracy: 0.5655 - val_loss: 1.2336 - val_accuracy: 0.5349

Epoch 00076: val_loss did not improve from 1.21637
Epoch 77/100
18218/18218 - 15s - loss: 1.1399 - accuracy: 0.5653 - val_loss: 1.2159 - val_accuracy: 0.5329

Epoch 00077: val_loss improved from 1.21637 to 1.21588, saving model to ./results/CNN_trial_7_4/cp.ckpt
Epoch 78/100
18218/18218 - 16s - loss: 1.1409 - accuracy: 0.5645 - val_loss: 1.2279 - val_accuracy: 0.5314

Epoch 00078: val_loss did not improve from 1.21588
Epoch 79/100
18218/18218 - 15s - loss: 1.1418 - accuracy: 0.5661 - val_loss: 1.2414 - val_accuracy: 0.5258

Epoch 00079: val_loss did not improve from 1.21588
Epoch 80/100
18218/18218 - 15s - loss: 1.1388 - accuracy: 0.5649 - val_loss: 1.2413 - val_accuracy: 0.5288

Epoch 00080: val_loss did not improve from 1.21588
Epoch 81/100
18218/18218 - 14s - loss: 1.1395 - accuracy: 0.5650 - val_loss: 1.2344 - val_accuracy: 0.5268

Epoch 00081: val_loss did not improve from 1.21588
Epoch 82/100
18218/18218 - 15s - loss: 1.1398 - accuracy: 0.5662 - val_loss: 1.2474 - val_accuracy: 0.5262

Epoch 00082: val_loss did not improve from 1.21588
Epoch 83/100
18218/18218 - 15s - loss: 1.1387 - accuracy: 0.5643 - val_loss: 1.2443 - val_accuracy: 0.5266

Epoch 00083: val_loss did not improve from 1.21588
Epoch 84/100
18218/18218 - 15s - loss: 1.1376 - accuracy: 0.5663 - val_loss: 1.2299 - val_accuracy: 0.5327

Epoch 00084: val_loss did not improve from 1.21588
Epoch 85/100
18218/18218 - 15s - loss: 1.1380 - accuracy: 0.5644 - val_loss: 1.2441 - val_accuracy: 0.5291

Epoch 00085: val_loss did not improve from 1.21588
Epoch 86/100
18218/18218 - 15s - loss: 1.1371 - accuracy: 0.5679 - val_loss: 1.2264 - val_accuracy: 0.5317

Epoch 00086: val_loss did not improve from 1.21588
Epoch 87/100
18218/18218 - 15s - loss: 1.1370 - accuracy: 0.5666 - val_loss: 1.2400 - val_accuracy: 0.5256

Epoch 00087: val_loss did not improve from 1.21588
Epoch 88/100
18218/18218 - 15s - loss: 1.1373 - accuracy: 0.5669 - val_loss: 1.2240 - val_accuracy: 0.5350

Epoch 00088: val_loss did not improve from 1.21588
Epoch 89/100
18218/18218 - 15s - loss: 1.1347 - accuracy: 0.5669 - val_loss: 1.2350 - val_accuracy: 0.5366

Epoch 00089: val_loss did not improve from 1.21588
Epoch 90/100
18218/18218 - 15s - loss: 1.1354 - accuracy: 0.5670 - val_loss: 1.2364 - val_accuracy: 0.5288

Epoch 00090: val_loss did not improve from 1.21588
Epoch 91/100
18218/18218 - 15s - loss: 1.1358 - accuracy: 0.5653 - val_loss: 1.2405 - val_accuracy: 0.5385

Epoch 00091: val_loss did not improve from 1.21588
Epoch 92/100
18218/18218 - 15s - loss: 1.1361 - accuracy: 0.5659 - val_loss: 1.2303 - val_accuracy: 0.5322

Epoch 00092: val_loss did not improve from 1.21588
Epoch 93/100
18218/18218 - 16s - loss: 1.1345 - accuracy: 0.5673 - val_loss: 1.2352 - val_accuracy: 0.5264

Epoch 00093: val_loss did not improve from 1.21588
Epoch 94/100
18218/18218 - 16s - loss: 1.1342 - accuracy: 0.5689 - val_loss: 1.2186 - val_accuracy: 0.5336

Epoch 00094: val_loss did not improve from 1.21588
Epoch 95/100
18218/18218 - 15s - loss: 1.1347 - accuracy: 0.5685 - val_loss: 1.2303 - val_accuracy: 0.5332

Epoch 00095: val_loss did not improve from 1.21588
Epoch 96/100
18218/18218 - 15s - loss: 1.1330 - accuracy: 0.5682 - val_loss: 1.2198 - val_accuracy: 0.5351

Epoch 00096: val_loss did not improve from 1.21588
Epoch 97/100
18218/18218 - 16s - loss: 1.1346 - accuracy: 0.5671 - val_loss: 1.2367 - val_accuracy: 0.5285

Epoch 00097: val_loss did not improve from 1.21588
Epoch 98/100
18218/18218 - 16s - loss: 1.1344 - accuracy: 0.5673 - val_loss: 1.2331 - val_accuracy: 0.5324

Epoch 00098: val_loss did not improve from 1.21588
Epoch 99/100
18218/18218 - 15s - loss: 1.1341 - accuracy: 0.5685 - val_loss: 1.2271 - val_accuracy: 0.5364

Epoch 00099: val_loss did not improve from 1.21588
Epoch 100/100
18218/18218 - 15s - loss: 1.1329 - accuracy: 0.5685 - val_loss: 1.2427 - val_accuracy: 0.5239

Epoch 00100: val_loss did not improve from 1.21588
