Before oversampling: Counter({0.0: 22772, 10.0: 15114, 50.0: 15085, 90.0: 15054, 30.0: 14964, 70.0: 14771, 92.0: 7628, 100.0: 7624})
After oversampling: Counter({100.0: 22772, 92.0: 22772, 90.0: 22772, 10.0: 22772, 0.0: 22772, 70.0: 22772, 50.0: 22772, 30.0: 22772})
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 19, 64)            512       
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 13, 64)            28736     
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 6, 64)             0         
_________________________________________________________________
flatten (Flatten)            (None, 384)               0         
_________________________________________________________________
dense (Dense)                (None, 22)                8470      
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 184       
=================================================================
Total params: 37,902
Trainable params: 37,902
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
18218/18218 - 16s - loss: 1.3984 - accuracy: 0.4492 - val_loss: 1.3295 - val_accuracy: 0.4701

Epoch 00001: val_loss improved from inf to 1.32950, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 2/100
18218/18218 - 16s - loss: 1.3106 - accuracy: 0.4896 - val_loss: 1.3113 - val_accuracy: 0.4731

Epoch 00002: val_loss improved from 1.32950 to 1.31129, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 3/100
18218/18218 - 16s - loss: 1.2744 - accuracy: 0.5034 - val_loss: 1.2752 - val_accuracy: 0.5031

Epoch 00003: val_loss improved from 1.31129 to 1.27524, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 4/100
18218/18218 - 16s - loss: 1.2534 - accuracy: 0.5137 - val_loss: 1.2801 - val_accuracy: 0.4987

Epoch 00004: val_loss did not improve from 1.27524
Epoch 5/100
18218/18218 - 16s - loss: 1.2415 - accuracy: 0.5182 - val_loss: 1.2958 - val_accuracy: 0.4920

Epoch 00005: val_loss did not improve from 1.27524
Epoch 6/100
18218/18218 - 16s - loss: 1.2327 - accuracy: 0.5214 - val_loss: 1.2556 - val_accuracy: 0.5078

Epoch 00006: val_loss improved from 1.27524 to 1.25563, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 7/100
18218/18218 - 16s - loss: 1.2261 - accuracy: 0.5235 - val_loss: 1.2655 - val_accuracy: 0.5112

Epoch 00007: val_loss did not improve from 1.25563
Epoch 8/100
18218/18218 - 16s - loss: 1.2182 - accuracy: 0.5280 - val_loss: 1.2718 - val_accuracy: 0.4929

Epoch 00008: val_loss did not improve from 1.25563
Epoch 9/100
18218/18218 - 16s - loss: 1.2127 - accuracy: 0.5314 - val_loss: 1.2506 - val_accuracy: 0.5158

Epoch 00009: val_loss improved from 1.25563 to 1.25057, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 10/100
18218/18218 - 16s - loss: 1.2075 - accuracy: 0.5322 - val_loss: 1.2317 - val_accuracy: 0.5224

Epoch 00010: val_loss improved from 1.25057 to 1.23173, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 11/100
18218/18218 - 16s - loss: 1.2025 - accuracy: 0.5350 - val_loss: 1.2377 - val_accuracy: 0.5134

Epoch 00011: val_loss did not improve from 1.23173
Epoch 12/100
18218/18218 - 16s - loss: 1.1982 - accuracy: 0.5369 - val_loss: 1.2441 - val_accuracy: 0.5102

Epoch 00012: val_loss did not improve from 1.23173
Epoch 13/100
18218/18218 - 16s - loss: 1.1942 - accuracy: 0.5377 - val_loss: 1.2451 - val_accuracy: 0.5134

Epoch 00013: val_loss did not improve from 1.23173
Epoch 14/100
18218/18218 - 17s - loss: 1.1909 - accuracy: 0.5401 - val_loss: 1.2790 - val_accuracy: 0.4956

Epoch 00014: val_loss did not improve from 1.23173
Epoch 15/100
18218/18218 - 17s - loss: 1.1863 - accuracy: 0.5433 - val_loss: 1.2583 - val_accuracy: 0.5100

Epoch 00015: val_loss did not improve from 1.23173
Epoch 16/100
18218/18218 - 16s - loss: 1.1850 - accuracy: 0.5428 - val_loss: 1.2335 - val_accuracy: 0.5232

Epoch 00016: val_loss did not improve from 1.23173
Epoch 17/100
18218/18218 - 16s - loss: 1.1810 - accuracy: 0.5449 - val_loss: 1.2444 - val_accuracy: 0.5169

Epoch 00017: val_loss did not improve from 1.23173
Epoch 18/100
18218/18218 - 16s - loss: 1.1776 - accuracy: 0.5459 - val_loss: 1.2488 - val_accuracy: 0.5180

Epoch 00018: val_loss did not improve from 1.23173
Epoch 19/100
18218/18218 - 16s - loss: 1.1758 - accuracy: 0.5479 - val_loss: 1.2266 - val_accuracy: 0.5244

Epoch 00019: val_loss improved from 1.23173 to 1.22660, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 20/100
18218/18218 - 16s - loss: 1.1724 - accuracy: 0.5500 - val_loss: 1.2249 - val_accuracy: 0.5276

Epoch 00020: val_loss improved from 1.22660 to 1.22491, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 21/100
18218/18218 - 16s - loss: 1.1712 - accuracy: 0.5499 - val_loss: 1.2340 - val_accuracy: 0.5246

Epoch 00021: val_loss did not improve from 1.22491
Epoch 22/100
18218/18218 - 16s - loss: 1.1690 - accuracy: 0.5507 - val_loss: 1.2197 - val_accuracy: 0.5292

Epoch 00022: val_loss improved from 1.22491 to 1.21968, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 23/100
18218/18218 - 16s - loss: 1.1663 - accuracy: 0.5528 - val_loss: 1.2526 - val_accuracy: 0.5211

Epoch 00023: val_loss did not improve from 1.21968
Epoch 24/100
18218/18218 - 16s - loss: 1.1648 - accuracy: 0.5526 - val_loss: 1.2299 - val_accuracy: 0.5267

Epoch 00024: val_loss did not improve from 1.21968
Epoch 25/100
18218/18218 - 17s - loss: 1.1624 - accuracy: 0.5537 - val_loss: 1.2283 - val_accuracy: 0.5214

Epoch 00025: val_loss did not improve from 1.21968
Epoch 26/100
18218/18218 - 17s - loss: 1.1613 - accuracy: 0.5559 - val_loss: 1.2465 - val_accuracy: 0.5108

Epoch 00026: val_loss did not improve from 1.21968
Epoch 27/100
18218/18218 - 16s - loss: 1.1602 - accuracy: 0.5538 - val_loss: 1.2311 - val_accuracy: 0.5281

Epoch 00027: val_loss did not improve from 1.21968
Epoch 28/100
18218/18218 - 16s - loss: 1.1581 - accuracy: 0.5569 - val_loss: 1.2376 - val_accuracy: 0.5274

Epoch 00028: val_loss did not improve from 1.21968
Epoch 29/100
18218/18218 - 16s - loss: 1.1574 - accuracy: 0.5573 - val_loss: 1.2337 - val_accuracy: 0.5166

Epoch 00029: val_loss did not improve from 1.21968
Epoch 30/100
18218/18218 - 16s - loss: 1.1553 - accuracy: 0.5554 - val_loss: 1.2258 - val_accuracy: 0.5270

Epoch 00030: val_loss did not improve from 1.21968
Epoch 31/100
18218/18218 - 16s - loss: 1.1528 - accuracy: 0.5567 - val_loss: 1.2420 - val_accuracy: 0.5215

Epoch 00031: val_loss did not improve from 1.21968
Epoch 32/100
18218/18218 - 16s - loss: 1.1538 - accuracy: 0.5570 - val_loss: 1.2313 - val_accuracy: 0.5246

Epoch 00032: val_loss did not improve from 1.21968
Epoch 33/100
18218/18218 - 16s - loss: 1.1510 - accuracy: 0.5579 - val_loss: 1.2362 - val_accuracy: 0.5208

Epoch 00033: val_loss did not improve from 1.21968
Epoch 34/100
18218/18218 - 16s - loss: 1.1505 - accuracy: 0.5601 - val_loss: 1.2390 - val_accuracy: 0.5169

Epoch 00034: val_loss did not improve from 1.21968
Epoch 35/100
18218/18218 - 16s - loss: 1.1469 - accuracy: 0.5601 - val_loss: 1.2243 - val_accuracy: 0.5276

Epoch 00035: val_loss did not improve from 1.21968
Epoch 36/100
18218/18218 - 16s - loss: 1.1470 - accuracy: 0.5596 - val_loss: 1.2321 - val_accuracy: 0.5203

Epoch 00036: val_loss did not improve from 1.21968
Epoch 37/100
18218/18218 - 16s - loss: 1.1457 - accuracy: 0.5596 - val_loss: 1.2471 - val_accuracy: 0.5155

Epoch 00037: val_loss did not improve from 1.21968
Epoch 38/100
18218/18218 - 16s - loss: 1.1430 - accuracy: 0.5612 - val_loss: 1.2219 - val_accuracy: 0.5204

Epoch 00038: val_loss did not improve from 1.21968
Epoch 39/100
18218/18218 - 16s - loss: 1.1427 - accuracy: 0.5593 - val_loss: 1.2259 - val_accuracy: 0.5266

Epoch 00039: val_loss did not improve from 1.21968
Epoch 40/100
18218/18218 - 16s - loss: 1.1424 - accuracy: 0.5621 - val_loss: 1.2197 - val_accuracy: 0.5271

Epoch 00040: val_loss did not improve from 1.21968
Epoch 41/100
18218/18218 - 16s - loss: 1.1423 - accuracy: 0.5615 - val_loss: 1.2182 - val_accuracy: 0.5321

Epoch 00041: val_loss improved from 1.21968 to 1.21817, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 42/100
18218/18218 - 16s - loss: 1.1392 - accuracy: 0.5630 - val_loss: 1.2280 - val_accuracy: 0.5225

Epoch 00042: val_loss did not improve from 1.21817
Epoch 43/100
18218/18218 - 16s - loss: 1.1392 - accuracy: 0.5629 - val_loss: 1.2250 - val_accuracy: 0.5344

Epoch 00043: val_loss did not improve from 1.21817
Epoch 44/100
18218/18218 - 16s - loss: 1.1385 - accuracy: 0.5635 - val_loss: 1.2162 - val_accuracy: 0.5248

Epoch 00044: val_loss improved from 1.21817 to 1.21615, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 45/100
18218/18218 - 16s - loss: 1.1372 - accuracy: 0.5631 - val_loss: 1.2226 - val_accuracy: 0.5324

Epoch 00045: val_loss did not improve from 1.21615
Epoch 46/100
18218/18218 - 16s - loss: 1.1354 - accuracy: 0.5653 - val_loss: 1.2287 - val_accuracy: 0.5290

Epoch 00046: val_loss did not improve from 1.21615
Epoch 47/100
18218/18218 - 16s - loss: 1.1348 - accuracy: 0.5639 - val_loss: 1.2191 - val_accuracy: 0.5273

Epoch 00047: val_loss did not improve from 1.21615
Epoch 48/100
18218/18218 - 16s - loss: 1.1326 - accuracy: 0.5650 - val_loss: 1.2212 - val_accuracy: 0.5254

Epoch 00048: val_loss did not improve from 1.21615
Epoch 49/100
18218/18218 - 16s - loss: 1.1324 - accuracy: 0.5649 - val_loss: 1.2257 - val_accuracy: 0.5238

Epoch 00049: val_loss did not improve from 1.21615
Epoch 50/100
18218/18218 - 16s - loss: 1.1317 - accuracy: 0.5674 - val_loss: 1.2208 - val_accuracy: 0.5260

Epoch 00050: val_loss did not improve from 1.21615
Epoch 51/100
18218/18218 - 16s - loss: 1.1302 - accuracy: 0.5682 - val_loss: 1.2419 - val_accuracy: 0.5236

Epoch 00051: val_loss did not improve from 1.21615
Epoch 52/100
18218/18218 - 16s - loss: 1.1302 - accuracy: 0.5683 - val_loss: 1.2122 - val_accuracy: 0.5332

Epoch 00052: val_loss improved from 1.21615 to 1.21221, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 53/100
18218/18218 - 16s - loss: 1.1291 - accuracy: 0.5680 - val_loss: 1.2263 - val_accuracy: 0.5261

Epoch 00053: val_loss did not improve from 1.21221
Epoch 54/100
18218/18218 - 16s - loss: 1.1286 - accuracy: 0.5686 - val_loss: 1.2191 - val_accuracy: 0.5305

Epoch 00054: val_loss did not improve from 1.21221
Epoch 55/100
18218/18218 - 17s - loss: 1.1269 - accuracy: 0.5679 - val_loss: 1.2177 - val_accuracy: 0.5339

Epoch 00055: val_loss did not improve from 1.21221
Epoch 56/100
18218/18218 - 16s - loss: 1.1263 - accuracy: 0.5689 - val_loss: 1.2359 - val_accuracy: 0.5200

Epoch 00056: val_loss did not improve from 1.21221
Epoch 57/100
18218/18218 - 16s - loss: 1.1254 - accuracy: 0.5697 - val_loss: 1.2063 - val_accuracy: 0.5424

Epoch 00057: val_loss improved from 1.21221 to 1.20633, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 58/100
18218/18218 - 16s - loss: 1.1257 - accuracy: 0.5689 - val_loss: 1.2233 - val_accuracy: 0.5269

Epoch 00058: val_loss did not improve from 1.20633
Epoch 59/100
18218/18218 - 16s - loss: 1.1240 - accuracy: 0.5704 - val_loss: 1.2067 - val_accuracy: 0.5387

Epoch 00059: val_loss did not improve from 1.20633
Epoch 60/100
18218/18218 - 16s - loss: 1.1243 - accuracy: 0.5676 - val_loss: 1.2196 - val_accuracy: 0.5322

Epoch 00060: val_loss did not improve from 1.20633
Epoch 61/100
18218/18218 - 16s - loss: 1.1234 - accuracy: 0.5691 - val_loss: 1.2268 - val_accuracy: 0.5309

Epoch 00061: val_loss did not improve from 1.20633
Epoch 62/100
18218/18218 - 16s - loss: 1.1214 - accuracy: 0.5708 - val_loss: 1.2327 - val_accuracy: 0.5228

Epoch 00062: val_loss did not improve from 1.20633
Epoch 63/100
18218/18218 - 16s - loss: 1.1218 - accuracy: 0.5703 - val_loss: 1.2377 - val_accuracy: 0.5289

Epoch 00063: val_loss did not improve from 1.20633
Epoch 64/100
18218/18218 - 16s - loss: 1.1206 - accuracy: 0.5713 - val_loss: 1.2349 - val_accuracy: 0.5358

Epoch 00064: val_loss did not improve from 1.20633
Epoch 65/100
18218/18218 - 16s - loss: 1.1211 - accuracy: 0.5718 - val_loss: 1.2148 - val_accuracy: 0.5370

Epoch 00065: val_loss did not improve from 1.20633
Epoch 66/100
18218/18218 - 16s - loss: 1.1204 - accuracy: 0.5723 - val_loss: 1.2585 - val_accuracy: 0.5214

Epoch 00066: val_loss did not improve from 1.20633
Epoch 67/100
18218/18218 - 16s - loss: 1.1199 - accuracy: 0.5709 - val_loss: 1.2238 - val_accuracy: 0.5289

Epoch 00067: val_loss did not improve from 1.20633
Epoch 68/100
18218/18218 - 16s - loss: 1.1189 - accuracy: 0.5712 - val_loss: 1.2444 - val_accuracy: 0.5246

Epoch 00068: val_loss did not improve from 1.20633
Epoch 69/100
18218/18218 - 16s - loss: 1.1174 - accuracy: 0.5720 - val_loss: 1.2262 - val_accuracy: 0.5416

Epoch 00069: val_loss did not improve from 1.20633
Epoch 70/100
18218/18218 - 16s - loss: 1.1183 - accuracy: 0.5719 - val_loss: 1.2149 - val_accuracy: 0.5243

Epoch 00070: val_loss did not improve from 1.20633
Epoch 71/100
18218/18218 - 16s - loss: 1.1160 - accuracy: 0.5734 - val_loss: 1.2150 - val_accuracy: 0.5410

Epoch 00071: val_loss did not improve from 1.20633
Epoch 72/100
18218/18218 - 16s - loss: 1.1168 - accuracy: 0.5725 - val_loss: 1.2214 - val_accuracy: 0.5326

Epoch 00072: val_loss did not improve from 1.20633
Epoch 73/100
18218/18218 - 15s - loss: 1.1160 - accuracy: 0.5733 - val_loss: 1.2278 - val_accuracy: 0.5302

Epoch 00073: val_loss did not improve from 1.20633
Epoch 74/100
18218/18218 - 16s - loss: 1.1150 - accuracy: 0.5732 - val_loss: 1.2368 - val_accuracy: 0.5241

Epoch 00074: val_loss did not improve from 1.20633
Epoch 75/100
18218/18218 - 16s - loss: 1.1152 - accuracy: 0.5747 - val_loss: 1.2141 - val_accuracy: 0.5348

Epoch 00075: val_loss did not improve from 1.20633
Epoch 76/100
18218/18218 - 16s - loss: 1.1152 - accuracy: 0.5746 - val_loss: 1.1983 - val_accuracy: 0.5387

Epoch 00076: val_loss improved from 1.20633 to 1.19831, saving model to ./results/CNN_trial_7_2/cp.ckpt
Epoch 77/100
18218/18218 - 16s - loss: 1.1133 - accuracy: 0.5753 - val_loss: 1.2214 - val_accuracy: 0.5315

Epoch 00077: val_loss did not improve from 1.19831
Epoch 78/100
18218/18218 - 16s - loss: 1.1127 - accuracy: 0.5761 - val_loss: 1.2345 - val_accuracy: 0.5261

Epoch 00078: val_loss did not improve from 1.19831
Epoch 79/100
18218/18218 - 16s - loss: 1.1133 - accuracy: 0.5756 - val_loss: 1.2267 - val_accuracy: 0.5291

Epoch 00079: val_loss did not improve from 1.19831
Epoch 80/100
18218/18218 - 16s - loss: 1.1127 - accuracy: 0.5738 - val_loss: 1.2249 - val_accuracy: 0.5347

Epoch 00080: val_loss did not improve from 1.19831
Epoch 81/100
18218/18218 - 16s - loss: 1.1129 - accuracy: 0.5743 - val_loss: 1.2238 - val_accuracy: 0.5253

Epoch 00081: val_loss did not improve from 1.19831
Epoch 82/100
18218/18218 - 16s - loss: 1.1123 - accuracy: 0.5756 - val_loss: 1.2372 - val_accuracy: 0.5315

Epoch 00082: val_loss did not improve from 1.19831
Epoch 83/100
18218/18218 - 16s - loss: 1.1120 - accuracy: 0.5753 - val_loss: 1.2103 - val_accuracy: 0.5298

Epoch 00083: val_loss did not improve from 1.19831
Epoch 84/100
18218/18218 - 16s - loss: 1.1107 - accuracy: 0.5757 - val_loss: 1.2127 - val_accuracy: 0.5396

Epoch 00084: val_loss did not improve from 1.19831
Epoch 85/100
18218/18218 - 16s - loss: 1.1100 - accuracy: 0.5755 - val_loss: 1.2315 - val_accuracy: 0.5285

Epoch 00085: val_loss did not improve from 1.19831
Epoch 86/100
18218/18218 - 16s - loss: 1.1095 - accuracy: 0.5773 - val_loss: 1.2485 - val_accuracy: 0.5262

Epoch 00086: val_loss did not improve from 1.19831
Epoch 87/100
18218/18218 - 16s - loss: 1.1103 - accuracy: 0.5753 - val_loss: 1.2290 - val_accuracy: 0.5261

Epoch 00087: val_loss did not improve from 1.19831
Epoch 88/100
18218/18218 - 16s - loss: 1.1100 - accuracy: 0.5755 - val_loss: 1.2418 - val_accuracy: 0.5301

Epoch 00088: val_loss did not improve from 1.19831
Epoch 89/100
18218/18218 - 16s - loss: 1.1080 - accuracy: 0.5765 - val_loss: 1.2194 - val_accuracy: 0.5329

Epoch 00089: val_loss did not improve from 1.19831
Epoch 90/100
18218/18218 - 16s - loss: 1.1082 - accuracy: 0.5772 - val_loss: 1.2328 - val_accuracy: 0.5294

Epoch 00090: val_loss did not improve from 1.19831
Epoch 91/100
18218/18218 - 16s - loss: 1.1086 - accuracy: 0.5776 - val_loss: 1.2411 - val_accuracy: 0.5320

Epoch 00091: val_loss did not improve from 1.19831
Epoch 92/100
18218/18218 - 16s - loss: 1.1081 - accuracy: 0.5771 - val_loss: 1.2219 - val_accuracy: 0.5318

Epoch 00092: val_loss did not improve from 1.19831
Epoch 93/100
18218/18218 - 17s - loss: 1.1074 - accuracy: 0.5771 - val_loss: 1.2218 - val_accuracy: 0.5342

Epoch 00093: val_loss did not improve from 1.19831
Epoch 94/100
18218/18218 - 16s - loss: 1.1069 - accuracy: 0.5771 - val_loss: 1.2195 - val_accuracy: 0.5344

Epoch 00094: val_loss did not improve from 1.19831
Epoch 95/100
18218/18218 - 16s - loss: 1.1070 - accuracy: 0.5780 - val_loss: 1.2208 - val_accuracy: 0.5311

Epoch 00095: val_loss did not improve from 1.19831
Epoch 96/100
18218/18218 - 17s - loss: 1.1066 - accuracy: 0.5773 - val_loss: 1.2270 - val_accuracy: 0.5358

Epoch 00096: val_loss did not improve from 1.19831
Epoch 97/100
18218/18218 - 17s - loss: 1.1066 - accuracy: 0.5782 - val_loss: 1.2374 - val_accuracy: 0.5356

Epoch 00097: val_loss did not improve from 1.19831
Epoch 98/100
18218/18218 - 16s - loss: 1.1052 - accuracy: 0.5783 - val_loss: 1.2107 - val_accuracy: 0.5413

Epoch 00098: val_loss did not improve from 1.19831
Epoch 99/100
18218/18218 - 16s - loss: 1.1053 - accuracy: 0.5797 - val_loss: 1.2341 - val_accuracy: 0.5272

Epoch 00099: val_loss did not improve from 1.19831
Epoch 100/100
18218/18218 - 16s - loss: 1.1049 - accuracy: 0.5789 - val_loss: 1.2141 - val_accuracy: 0.5374

Epoch 00100: val_loss did not improve from 1.19831
