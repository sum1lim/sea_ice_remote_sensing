Before oversampling: Counter({50.0: 52538, 10.0: 30078, 0.0: 22772, 100.0: 7624})
After oversampling: Counter({100.0: 52538, 50.0: 52538, 10.0: 52538, 0.0: 52538})
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
conv (InputLayer)               [(None, 23, 1)]      0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 23, 64)       384         conv[0][0]                       
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 23, 64)       20544       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 23, 64)       20544       conv1d_1[0][0]                   
__________________________________________________________________________________________________
cat (InputLayer)                [(None, 2)]          0                                            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1472)         0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 1474)         0           cat[0][0]                        
                                                                 flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 16)           23600       concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 4)            68          dense[0][0]                      
==================================================================================================
Total params: 65,140
Trainable params: 65,140
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
21016/21016 - 20s - loss: 0.7021 - accuracy: 0.7073 - val_loss: 0.7125 - val_accuracy: 0.6945

Epoch 00001: val_loss improved from inf to 0.71249, saving model to ./results/CNN_GLCM_C4_cat/cp.ckpt
Epoch 2/100
21016/21016 - 19s - loss: 0.6033 - accuracy: 0.7653 - val_loss: 0.7261 - val_accuracy: 0.6879

Epoch 00002: val_loss did not improve from 0.71249
Epoch 3/100
21016/21016 - 19s - loss: 0.5603 - accuracy: 0.7840 - val_loss: 0.7742 - val_accuracy: 0.6902

Epoch 00003: val_loss did not improve from 0.71249
Epoch 4/100
21016/21016 - 19s - loss: 0.5380 - accuracy: 0.7926 - val_loss: 0.7661 - val_accuracy: 0.6999

Epoch 00004: val_loss did not improve from 0.71249
Epoch 5/100
21016/21016 - 19s - loss: 0.5190 - accuracy: 0.8010 - val_loss: 0.8185 - val_accuracy: 0.7010

Epoch 00005: val_loss did not improve from 0.71249
Epoch 6/100
21016/21016 - 19s - loss: 0.5052 - accuracy: 0.8065 - val_loss: 0.7930 - val_accuracy: 0.7082

Epoch 00006: val_loss did not improve from 0.71249
Epoch 7/100
21016/21016 - 19s - loss: 0.4967 - accuracy: 0.8117 - val_loss: 0.7326 - val_accuracy: 0.7179

Epoch 00007: val_loss did not improve from 0.71249
Epoch 8/100
21016/21016 - 19s - loss: 0.4889 - accuracy: 0.8149 - val_loss: 0.8049 - val_accuracy: 0.7019

Epoch 00008: val_loss did not improve from 0.71249
Epoch 9/100
21016/21016 - 19s - loss: 0.4846 - accuracy: 0.8156 - val_loss: 0.7690 - val_accuracy: 0.7152

Epoch 00009: val_loss did not improve from 0.71249
Epoch 10/100
21016/21016 - 19s - loss: 0.4807 - accuracy: 0.8169 - val_loss: 0.7442 - val_accuracy: 0.7321

Epoch 00010: val_loss did not improve from 0.71249
Epoch 11/100
21016/21016 - 19s - loss: 0.4788 - accuracy: 0.8173 - val_loss: 0.7660 - val_accuracy: 0.7331

Epoch 00011: val_loss did not improve from 0.71249
Epoch 12/100
21016/21016 - 19s - loss: 0.4742 - accuracy: 0.8191 - val_loss: 0.7768 - val_accuracy: 0.7278

Epoch 00012: val_loss did not improve from 0.71249
Epoch 13/100
21016/21016 - 19s - loss: 0.4708 - accuracy: 0.8199 - val_loss: 0.8060 - val_accuracy: 0.7182

Epoch 00013: val_loss did not improve from 0.71249
Epoch 14/100
21016/21016 - 19s - loss: 0.4676 - accuracy: 0.8212 - val_loss: 0.7486 - val_accuracy: 0.7215

Epoch 00014: val_loss did not improve from 0.71249
Epoch 15/100
21016/21016 - 19s - loss: 0.4663 - accuracy: 0.8219 - val_loss: 0.7629 - val_accuracy: 0.7239

Epoch 00015: val_loss did not improve from 0.71249
Epoch 16/100
21016/21016 - 19s - loss: 0.4632 - accuracy: 0.8228 - val_loss: 0.7501 - val_accuracy: 0.7234

Epoch 00016: val_loss did not improve from 0.71249
Epoch 17/100
21016/21016 - 19s - loss: 0.4611 - accuracy: 0.8243 - val_loss: 0.7718 - val_accuracy: 0.7195

Epoch 00017: val_loss did not improve from 0.71249
Epoch 18/100
21016/21016 - 19s - loss: 0.4607 - accuracy: 0.8248 - val_loss: 0.7207 - val_accuracy: 0.7328

Epoch 00018: val_loss did not improve from 0.71249
Epoch 19/100
21016/21016 - 19s - loss: 0.4590 - accuracy: 0.8253 - val_loss: 0.7565 - val_accuracy: 0.7283

Epoch 00019: val_loss did not improve from 0.71249
Epoch 20/100
21016/21016 - 19s - loss: 0.4569 - accuracy: 0.8262 - val_loss: 0.7527 - val_accuracy: 0.7286

Epoch 00020: val_loss did not improve from 0.71249
Epoch 21/100
21016/21016 - 19s - loss: 0.4556 - accuracy: 0.8260 - val_loss: 0.7595 - val_accuracy: 0.7300

Epoch 00021: val_loss did not improve from 0.71249
Epoch 22/100
21016/21016 - 19s - loss: 0.4537 - accuracy: 0.8276 - val_loss: 0.7987 - val_accuracy: 0.7194

Epoch 00022: val_loss did not improve from 0.71249
Epoch 23/100
21016/21016 - 19s - loss: 0.4516 - accuracy: 0.8287 - val_loss: 0.8035 - val_accuracy: 0.7230

Epoch 00023: val_loss did not improve from 0.71249
Epoch 24/100
21016/21016 - 19s - loss: 0.4533 - accuracy: 0.8283 - val_loss: 0.7907 - val_accuracy: 0.7242

Epoch 00024: val_loss did not improve from 0.71249
Epoch 25/100
21016/21016 - 19s - loss: 0.4512 - accuracy: 0.8293 - val_loss: 0.8360 - val_accuracy: 0.7111

Epoch 00025: val_loss did not improve from 0.71249
Epoch 26/100
21016/21016 - 19s - loss: 0.4510 - accuracy: 0.8297 - val_loss: 0.7652 - val_accuracy: 0.7291

Epoch 00026: val_loss did not improve from 0.71249
Epoch 27/100
21016/21016 - 19s - loss: 0.4500 - accuracy: 0.8293 - val_loss: 0.8330 - val_accuracy: 0.7201

Epoch 00027: val_loss did not improve from 0.71249
Epoch 28/100
21016/21016 - 19s - loss: 0.4500 - accuracy: 0.8300 - val_loss: 0.8096 - val_accuracy: 0.7311

Epoch 00028: val_loss did not improve from 0.71249
Epoch 29/100
21016/21016 - 19s - loss: 0.4492 - accuracy: 0.8302 - val_loss: 0.7877 - val_accuracy: 0.7337

Epoch 00029: val_loss did not improve from 0.71249
Epoch 30/100
21016/21016 - 19s - loss: 0.4479 - accuracy: 0.8302 - val_loss: 0.7955 - val_accuracy: 0.7342

Epoch 00030: val_loss did not improve from 0.71249
Epoch 31/100
21016/21016 - 19s - loss: 0.4472 - accuracy: 0.8305 - val_loss: 0.7664 - val_accuracy: 0.7320

Epoch 00031: val_loss did not improve from 0.71249
Epoch 32/100
21016/21016 - 19s - loss: 0.4463 - accuracy: 0.8303 - val_loss: 0.8760 - val_accuracy: 0.7214

Epoch 00032: val_loss did not improve from 0.71249
Epoch 33/100
21016/21016 - 19s - loss: 0.4465 - accuracy: 0.8300 - val_loss: 0.7854 - val_accuracy: 0.7296

Epoch 00033: val_loss did not improve from 0.71249
Epoch 34/100
21016/21016 - 19s - loss: 0.4471 - accuracy: 0.8307 - val_loss: 0.8032 - val_accuracy: 0.7339

Epoch 00034: val_loss did not improve from 0.71249
Epoch 35/100
21016/21016 - 19s - loss: 0.4465 - accuracy: 0.8315 - val_loss: 0.7849 - val_accuracy: 0.7322

Epoch 00035: val_loss did not improve from 0.71249
Epoch 36/100
21016/21016 - 19s - loss: 0.4471 - accuracy: 0.8305 - val_loss: 0.7742 - val_accuracy: 0.7305

Epoch 00036: val_loss did not improve from 0.71249
Epoch 37/100
21016/21016 - 19s - loss: 0.4453 - accuracy: 0.8313 - val_loss: 0.8047 - val_accuracy: 0.7306

Epoch 00037: val_loss did not improve from 0.71249
Epoch 38/100
21016/21016 - 19s - loss: 0.4450 - accuracy: 0.8310 - val_loss: 0.8286 - val_accuracy: 0.7169

Epoch 00038: val_loss did not improve from 0.71249
Epoch 39/100
21016/21016 - 19s - loss: 0.4443 - accuracy: 0.8307 - val_loss: 0.8731 - val_accuracy: 0.7151

Epoch 00039: val_loss did not improve from 0.71249
Epoch 40/100
21016/21016 - 19s - loss: 0.4458 - accuracy: 0.8301 - val_loss: 0.7988 - val_accuracy: 0.7365

Epoch 00040: val_loss did not improve from 0.71249
Epoch 41/100
21016/21016 - 19s - loss: 0.4464 - accuracy: 0.8315 - val_loss: 0.7886 - val_accuracy: 0.7204

Epoch 00041: val_loss did not improve from 0.71249
Epoch 42/100
21016/21016 - 19s - loss: 0.4451 - accuracy: 0.8314 - val_loss: 0.7143 - val_accuracy: 0.7434

Epoch 00042: val_loss did not improve from 0.71249
Epoch 43/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8310 - val_loss: 0.7685 - val_accuracy: 0.7283

Epoch 00043: val_loss did not improve from 0.71249
Epoch 44/100
21016/21016 - 19s - loss: 0.4434 - accuracy: 0.8320 - val_loss: 0.7860 - val_accuracy: 0.7305

Epoch 00044: val_loss did not improve from 0.71249
Epoch 45/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8314 - val_loss: 0.8242 - val_accuracy: 0.7212

Epoch 00045: val_loss did not improve from 0.71249
Epoch 46/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8325 - val_loss: 0.8593 - val_accuracy: 0.7142

Epoch 00046: val_loss did not improve from 0.71249
Epoch 47/100
21016/21016 - 19s - loss: 0.4444 - accuracy: 0.8316 - val_loss: 0.8227 - val_accuracy: 0.7185

Epoch 00047: val_loss did not improve from 0.71249
Epoch 48/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8316 - val_loss: 0.7955 - val_accuracy: 0.7297

Epoch 00048: val_loss did not improve from 0.71249
Epoch 49/100
21016/21016 - 19s - loss: 0.4442 - accuracy: 0.8319 - val_loss: 0.7944 - val_accuracy: 0.7282

Epoch 00049: val_loss did not improve from 0.71249
Epoch 50/100
21016/21016 - 19s - loss: 0.4444 - accuracy: 0.8314 - val_loss: 0.7854 - val_accuracy: 0.7270

Epoch 00050: val_loss did not improve from 0.71249
Epoch 51/100
21016/21016 - 19s - loss: 0.4426 - accuracy: 0.8314 - val_loss: 0.8361 - val_accuracy: 0.7210

Epoch 00051: val_loss did not improve from 0.71249
Epoch 52/100
21016/21016 - 19s - loss: 0.4444 - accuracy: 0.8314 - val_loss: 0.7899 - val_accuracy: 0.7345

Epoch 00052: val_loss did not improve from 0.71249
Epoch 53/100
21016/21016 - 19s - loss: 0.4436 - accuracy: 0.8318 - val_loss: 0.7874 - val_accuracy: 0.7339

Epoch 00053: val_loss did not improve from 0.71249
Epoch 54/100
21016/21016 - 19s - loss: 0.4436 - accuracy: 0.8322 - val_loss: 0.8045 - val_accuracy: 0.7259

Epoch 00054: val_loss did not improve from 0.71249
Epoch 55/100
21016/21016 - 19s - loss: 0.4428 - accuracy: 0.8326 - val_loss: 0.7993 - val_accuracy: 0.7354

Epoch 00055: val_loss did not improve from 0.71249
Epoch 56/100
21016/21016 - 19s - loss: 0.4437 - accuracy: 0.8313 - val_loss: 0.8066 - val_accuracy: 0.7308

Epoch 00056: val_loss did not improve from 0.71249
Epoch 57/100
21016/21016 - 19s - loss: 0.4422 - accuracy: 0.8317 - val_loss: 0.8273 - val_accuracy: 0.7280

Epoch 00057: val_loss did not improve from 0.71249
Epoch 58/100
21016/21016 - 19s - loss: 0.4423 - accuracy: 0.8317 - val_loss: 0.8252 - val_accuracy: 0.7260

Epoch 00058: val_loss did not improve from 0.71249
Epoch 59/100
21016/21016 - 19s - loss: 0.4430 - accuracy: 0.8326 - val_loss: 0.8239 - val_accuracy: 0.7324

Epoch 00059: val_loss did not improve from 0.71249
Epoch 60/100
21016/21016 - 19s - loss: 0.4441 - accuracy: 0.8318 - val_loss: 0.8387 - val_accuracy: 0.7256

Epoch 00060: val_loss did not improve from 0.71249
Epoch 61/100
21016/21016 - 19s - loss: 0.4435 - accuracy: 0.8323 - val_loss: 0.7603 - val_accuracy: 0.7381

Epoch 00061: val_loss did not improve from 0.71249
Epoch 62/100
21016/21016 - 19s - loss: 0.4455 - accuracy: 0.8317 - val_loss: 0.7783 - val_accuracy: 0.7303

Epoch 00062: val_loss did not improve from 0.71249
Epoch 63/100
21016/21016 - 19s - loss: 0.4439 - accuracy: 0.8312 - val_loss: 0.8395 - val_accuracy: 0.7255

Epoch 00063: val_loss did not improve from 0.71249
Epoch 64/100
21016/21016 - 19s - loss: 0.4432 - accuracy: 0.8326 - val_loss: 0.7791 - val_accuracy: 0.7360

Epoch 00064: val_loss did not improve from 0.71249
Epoch 65/100
21016/21016 - 19s - loss: 0.4437 - accuracy: 0.8319 - val_loss: 0.8546 - val_accuracy: 0.7170

Epoch 00065: val_loss did not improve from 0.71249
Epoch 66/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8318 - val_loss: 0.7612 - val_accuracy: 0.7336

Epoch 00066: val_loss did not improve from 0.71249
Epoch 67/100
21016/21016 - 19s - loss: 0.4438 - accuracy: 0.8309 - val_loss: 0.8217 - val_accuracy: 0.7251

Epoch 00067: val_loss did not improve from 0.71249
Epoch 68/100
21016/21016 - 19s - loss: 0.4427 - accuracy: 0.8322 - val_loss: 0.8184 - val_accuracy: 0.7301

Epoch 00068: val_loss did not improve from 0.71249
Epoch 69/100
21016/21016 - 19s - loss: 0.4406 - accuracy: 0.8336 - val_loss: 0.7862 - val_accuracy: 0.7285

Epoch 00069: val_loss did not improve from 0.71249
Epoch 70/100
21016/21016 - 19s - loss: 0.4414 - accuracy: 0.8320 - val_loss: 0.8377 - val_accuracy: 0.7207

Epoch 00070: val_loss did not improve from 0.71249
Epoch 71/100
21016/21016 - 19s - loss: 0.4424 - accuracy: 0.8327 - val_loss: 0.8673 - val_accuracy: 0.7188

Epoch 00071: val_loss did not improve from 0.71249
Epoch 72/100
21016/21016 - 19s - loss: 0.4432 - accuracy: 0.8323 - val_loss: 0.8288 - val_accuracy: 0.7214

Epoch 00072: val_loss did not improve from 0.71249
Epoch 73/100
21016/21016 - 19s - loss: 0.4414 - accuracy: 0.8324 - val_loss: 0.7989 - val_accuracy: 0.7267

Epoch 00073: val_loss did not improve from 0.71249
Epoch 74/100
21016/21016 - 19s - loss: 0.4454 - accuracy: 0.8312 - val_loss: 0.8261 - val_accuracy: 0.7257

Epoch 00074: val_loss did not improve from 0.71249
Epoch 75/100
21016/21016 - 19s - loss: 0.4435 - accuracy: 0.8316 - val_loss: 1.3305 - val_accuracy: 0.7139

Epoch 00075: val_loss did not improve from 0.71249
Epoch 76/100
21016/21016 - 19s - loss: 0.4442 - accuracy: 0.8317 - val_loss: 0.7634 - val_accuracy: 0.7356

Epoch 00076: val_loss did not improve from 0.71249
Epoch 77/100
21016/21016 - 19s - loss: 0.4436 - accuracy: 0.8311 - val_loss: 0.8283 - val_accuracy: 0.7327

Epoch 00077: val_loss did not improve from 0.71249
Epoch 78/100
21016/21016 - 19s - loss: 0.4449 - accuracy: 0.8314 - val_loss: 0.8229 - val_accuracy: 0.7251

Epoch 00078: val_loss did not improve from 0.71249
Epoch 79/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8320 - val_loss: 0.7999 - val_accuracy: 0.7268

Epoch 00079: val_loss did not improve from 0.71249
Epoch 80/100
21016/21016 - 19s - loss: 0.4426 - accuracy: 0.8314 - val_loss: 0.7990 - val_accuracy: 0.7326

Epoch 00080: val_loss did not improve from 0.71249
Epoch 81/100
21016/21016 - 19s - loss: 0.4438 - accuracy: 0.8316 - val_loss: 0.8314 - val_accuracy: 0.7244

Epoch 00081: val_loss did not improve from 0.71249
Epoch 82/100
21016/21016 - 19s - loss: 0.4445 - accuracy: 0.8325 - val_loss: 0.7452 - val_accuracy: 0.7390

Epoch 00082: val_loss did not improve from 0.71249
Epoch 83/100
21016/21016 - 20s - loss: 0.4435 - accuracy: 0.8318 - val_loss: 0.8495 - val_accuracy: 0.7263

Epoch 00083: val_loss did not improve from 0.71249
Epoch 84/100
21016/21016 - 19s - loss: 0.4448 - accuracy: 0.8321 - val_loss: 0.8226 - val_accuracy: 0.7142

Epoch 00084: val_loss did not improve from 0.71249
Epoch 85/100
21016/21016 - 20s - loss: 0.4449 - accuracy: 0.8313 - val_loss: 0.8407 - val_accuracy: 0.7248

Epoch 00085: val_loss did not improve from 0.71249
Epoch 86/100
21016/21016 - 19s - loss: 0.4446 - accuracy: 0.8314 - val_loss: 0.8249 - val_accuracy: 0.7259

Epoch 00086: val_loss did not improve from 0.71249
Epoch 87/100
21016/21016 - 19s - loss: 0.4447 - accuracy: 0.8320 - val_loss: 0.8117 - val_accuracy: 0.7330

Epoch 00087: val_loss did not improve from 0.71249
Epoch 88/100
21016/21016 - 20s - loss: 0.4430 - accuracy: 0.8326 - val_loss: 0.7947 - val_accuracy: 0.7352

Epoch 00088: val_loss did not improve from 0.71249
Epoch 89/100
21016/21016 - 19s - loss: 0.4465 - accuracy: 0.8314 - val_loss: 0.8887 - val_accuracy: 0.7204

Epoch 00089: val_loss did not improve from 0.71249
Epoch 90/100
21016/21016 - 19s - loss: 0.4426 - accuracy: 0.8314 - val_loss: 0.8059 - val_accuracy: 0.7350

Epoch 00090: val_loss did not improve from 0.71249
Epoch 91/100
21016/21016 - 19s - loss: 0.4442 - accuracy: 0.8301 - val_loss: 0.8152 - val_accuracy: 0.7283

Epoch 00091: val_loss did not improve from 0.71249
Epoch 92/100
21016/21016 - 19s - loss: 0.4419 - accuracy: 0.8330 - val_loss: 0.7762 - val_accuracy: 0.7369

Epoch 00092: val_loss did not improve from 0.71249
Epoch 93/100
21016/21016 - 19s - loss: 0.4433 - accuracy: 0.8325 - val_loss: 0.7868 - val_accuracy: 0.7371

Epoch 00093: val_loss did not improve from 0.71249
Epoch 94/100
21016/21016 - 19s - loss: 0.4440 - accuracy: 0.8326 - val_loss: 0.7937 - val_accuracy: 0.7349

Epoch 00094: val_loss did not improve from 0.71249
Epoch 95/100
21016/21016 - 19s - loss: 0.4415 - accuracy: 0.8327 - val_loss: 0.7879 - val_accuracy: 0.7370

Epoch 00095: val_loss did not improve from 0.71249
Epoch 96/100
21016/21016 - 19s - loss: 0.4440 - accuracy: 0.8320 - val_loss: 0.7763 - val_accuracy: 0.7388

Epoch 00096: val_loss did not improve from 0.71249
Epoch 97/100
21016/21016 - 19s - loss: 0.4438 - accuracy: 0.8318 - val_loss: 0.7695 - val_accuracy: 0.7344

Epoch 00097: val_loss did not improve from 0.71249
Epoch 98/100
21016/21016 - 19s - loss: 0.4421 - accuracy: 0.8321 - val_loss: 0.7676 - val_accuracy: 0.7412

Epoch 00098: val_loss did not improve from 0.71249
Epoch 99/100
21016/21016 - 19s - loss: 0.4423 - accuracy: 0.8326 - val_loss: 0.8206 - val_accuracy: 0.7292

Epoch 00099: val_loss did not improve from 0.71249
Epoch 100/100
21016/21016 - 19s - loss: 0.4429 - accuracy: 0.8310 - val_loss: 0.8060 - val_accuracy: 0.7401

Epoch 00100: val_loss did not improve from 0.71249
