Before oversampling: Counter({92.0: 7628, 100.0: 7624, 91.0: 7615, 0.0: 7615, 60.0: 7609, 10.0: 7595, 70.0: 7583, 1.0: 7580, 2.0: 7577, 20.0: 7519, 40.0: 7516, 50.0: 7476, 30.0: 7448, 90.0: 7439, 80.0: 7188})
After oversampling: Counter({100.0: 7628, 92.0: 7628, 91.0: 7628, 90.0: 7628, 20.0: 7628, 1.0: 7628, 80.0: 7628, 70.0: 7628, 0.0: 7628, 50.0: 7628, 30.0: 7628, 10.0: 7628, 40.0: 7628, 2.0: 7628, 60.0: 7628})
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
conv (InputLayer)               [(None, 23, 1)]      0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 19, 64)       384         conv[0][0]                       
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 15, 64)       20544       conv1d[0][0]                     
__________________________________________________________________________________________________
cat (InputLayer)                [(None, 2)]          0                                            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 960)          0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 962)          0           cat[0][0]                        
                                                                 flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 23)           22149       concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 23)           0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 15)           360         dropout[0][0]                    
==================================================================================================
Total params: 43,437
Trainable params: 43,437
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
11442/11442 - 8s - loss: 2.2640 - accuracy: 0.2068 - val_loss: 2.2942 - val_accuracy: 0.2148

Epoch 00001: val_loss improved from inf to 2.29418, saving model to ./results/CNN_GLCM_C15_cat/cp.ckpt
Epoch 2/100
11442/11442 - 9s - loss: 2.1847 - accuracy: 0.2312 - val_loss: 2.3826 - val_accuracy: 0.2001

Epoch 00002: val_loss did not improve from 2.29418
Epoch 3/100
11442/11442 - 8s - loss: 2.1578 - accuracy: 0.2489 - val_loss: 2.2423 - val_accuracy: 0.2290

Epoch 00003: val_loss improved from 2.29418 to 2.24226, saving model to ./results/CNN_GLCM_C15_cat/cp.ckpt
Epoch 4/100
11442/11442 - 8s - loss: 2.1462 - accuracy: 0.2565 - val_loss: 2.4126 - val_accuracy: 0.2601

Epoch 00004: val_loss did not improve from 2.24226
Epoch 5/100
11442/11442 - 8s - loss: 2.1285 - accuracy: 0.2650 - val_loss: 2.1790 - val_accuracy: 0.2428

Epoch 00005: val_loss improved from 2.24226 to 2.17904, saving model to ./results/CNN_GLCM_C15_cat/cp.ckpt
Epoch 6/100
11442/11442 - 8s - loss: 2.1229 - accuracy: 0.2632 - val_loss: 2.2785 - val_accuracy: 0.2177

Epoch 00006: val_loss did not improve from 2.17904
Epoch 7/100
11442/11442 - 8s - loss: 2.1164 - accuracy: 0.2694 - val_loss: 2.3423 - val_accuracy: 0.2526

Epoch 00007: val_loss did not improve from 2.17904
Epoch 8/100
11442/11442 - 8s - loss: 2.1230 - accuracy: 0.2714 - val_loss: 2.4101 - val_accuracy: 0.2077

Epoch 00008: val_loss did not improve from 2.17904
Epoch 9/100
11442/11442 - 8s - loss: 2.0984 - accuracy: 0.2787 - val_loss: 2.2587 - val_accuracy: 0.2297

Epoch 00009: val_loss did not improve from 2.17904
Epoch 10/100
11442/11442 - 8s - loss: 2.1019 - accuracy: 0.2797 - val_loss: 2.2086 - val_accuracy: 0.2419

Epoch 00010: val_loss did not improve from 2.17904
Epoch 11/100
11442/11442 - 8s - loss: 2.1047 - accuracy: 0.2823 - val_loss: 2.2754 - val_accuracy: 0.2286

Epoch 00011: val_loss did not improve from 2.17904
Epoch 12/100
11442/11442 - 8s - loss: 2.1149 - accuracy: 0.2828 - val_loss: 2.2643 - val_accuracy: 0.2149

Epoch 00012: val_loss did not improve from 2.17904
Epoch 13/100
11442/11442 - 8s - loss: 2.1046 - accuracy: 0.2872 - val_loss: 2.2179 - val_accuracy: 0.2443

Epoch 00013: val_loss did not improve from 2.17904
Epoch 14/100
11442/11442 - 8s - loss: 2.1080 - accuracy: 0.2893 - val_loss: 2.2607 - val_accuracy: 0.2224

Epoch 00014: val_loss did not improve from 2.17904
Epoch 15/100
11442/11442 - 8s - loss: 2.1056 - accuracy: 0.2885 - val_loss: 2.2934 - val_accuracy: 0.2015

Epoch 00015: val_loss did not improve from 2.17904
Epoch 16/100
11442/11442 - 8s - loss: 2.1019 - accuracy: 0.2948 - val_loss: 2.3612 - val_accuracy: 0.2532

Epoch 00016: val_loss did not improve from 2.17904
Epoch 17/100
11442/11442 - 8s - loss: 2.0923 - accuracy: 0.2970 - val_loss: 2.3515 - val_accuracy: 0.2383

Epoch 00017: val_loss did not improve from 2.17904
Epoch 18/100
11442/11442 - 9s - loss: 2.0868 - accuracy: 0.3003 - val_loss: 2.3889 - val_accuracy: 0.2034

Epoch 00018: val_loss did not improve from 2.17904
Epoch 19/100
11442/11442 - 8s - loss: 2.0906 - accuracy: 0.3006 - val_loss: 2.3704 - val_accuracy: 0.2349

Epoch 00019: val_loss did not improve from 2.17904
Epoch 20/100
11442/11442 - 8s - loss: 2.0936 - accuracy: 0.3053 - val_loss: 2.2320 - val_accuracy: 0.2265

Epoch 00020: val_loss did not improve from 2.17904
Epoch 21/100
11442/11442 - 8s - loss: 2.0809 - accuracy: 0.3033 - val_loss: 2.2906 - val_accuracy: 0.2507

Epoch 00021: val_loss did not improve from 2.17904
Epoch 22/100
11442/11442 - 8s - loss: 2.0909 - accuracy: 0.3063 - val_loss: 2.3266 - val_accuracy: 0.2301

Epoch 00022: val_loss did not improve from 2.17904
Epoch 23/100
11442/11442 - 8s - loss: 2.0919 - accuracy: 0.3053 - val_loss: 2.2977 - val_accuracy: 0.2270

Epoch 00023: val_loss did not improve from 2.17904
Epoch 24/100
11442/11442 - 8s - loss: 2.0933 - accuracy: 0.3070 - val_loss: 2.3568 - val_accuracy: 0.2310

Epoch 00024: val_loss did not improve from 2.17904
Epoch 25/100
11442/11442 - 8s - loss: 2.0915 - accuracy: 0.3089 - val_loss: 2.3758 - val_accuracy: 0.2321

Epoch 00025: val_loss did not improve from 2.17904
Epoch 26/100
11442/11442 - 8s - loss: 2.0998 - accuracy: 0.3073 - val_loss: 2.3685 - val_accuracy: 0.2539

Epoch 00026: val_loss did not improve from 2.17904
Epoch 27/100
11442/11442 - 8s - loss: 2.0757 - accuracy: 0.3135 - val_loss: 2.4168 - val_accuracy: 0.2564

Epoch 00027: val_loss did not improve from 2.17904
Epoch 28/100
11442/11442 - 8s - loss: 2.0956 - accuracy: 0.3101 - val_loss: 2.3386 - val_accuracy: 0.2506

Epoch 00028: val_loss did not improve from 2.17904
Epoch 29/100
11442/11442 - 8s - loss: 2.0883 - accuracy: 0.3146 - val_loss: 2.3670 - val_accuracy: 0.1918

Epoch 00029: val_loss did not improve from 2.17904
Epoch 30/100
11442/11442 - 8s - loss: 2.0872 - accuracy: 0.3150 - val_loss: 2.2922 - val_accuracy: 0.2628

Epoch 00030: val_loss did not improve from 2.17904
Epoch 31/100
11442/11442 - 8s - loss: 2.0865 - accuracy: 0.3140 - val_loss: 2.5801 - val_accuracy: 0.2291

Epoch 00031: val_loss did not improve from 2.17904
Epoch 32/100
11442/11442 - 8s - loss: 2.0757 - accuracy: 0.3172 - val_loss: 2.2269 - val_accuracy: 0.2471

Epoch 00032: val_loss did not improve from 2.17904
Epoch 33/100
11442/11442 - 8s - loss: 2.0811 - accuracy: 0.3172 - val_loss: 2.6195 - val_accuracy: 0.2445

Epoch 00033: val_loss did not improve from 2.17904
Epoch 34/100
11442/11442 - 8s - loss: 2.0793 - accuracy: 0.3188 - val_loss: 2.4876 - val_accuracy: 0.2575

Epoch 00034: val_loss did not improve from 2.17904
Epoch 35/100
11442/11442 - 8s - loss: 2.0980 - accuracy: 0.3197 - val_loss: 2.3588 - val_accuracy: 0.2582

Epoch 00035: val_loss did not improve from 2.17904
Epoch 36/100
11442/11442 - 8s - loss: 2.1021 - accuracy: 0.3208 - val_loss: 2.3724 - val_accuracy: 0.2659

Epoch 00036: val_loss did not improve from 2.17904
Epoch 37/100
11442/11442 - 8s - loss: 2.0905 - accuracy: 0.3201 - val_loss: 2.6613 - val_accuracy: 0.2135

Epoch 00037: val_loss did not improve from 2.17904
Epoch 38/100
11442/11442 - 8s - loss: 2.0793 - accuracy: 0.3238 - val_loss: 2.3753 - val_accuracy: 0.2679

Epoch 00038: val_loss did not improve from 2.17904
Epoch 39/100
11442/11442 - 8s - loss: 2.0845 - accuracy: 0.3220 - val_loss: 2.5031 - val_accuracy: 0.2581

Epoch 00039: val_loss did not improve from 2.17904
Epoch 40/100
11442/11442 - 8s - loss: 2.0772 - accuracy: 0.3264 - val_loss: 2.4364 - val_accuracy: 0.2605

Epoch 00040: val_loss did not improve from 2.17904
Epoch 41/100
11442/11442 - 8s - loss: 2.0857 - accuracy: 0.3221 - val_loss: 2.4294 - val_accuracy: 0.2617

Epoch 00041: val_loss did not improve from 2.17904
Epoch 42/100
11442/11442 - 8s - loss: 2.0748 - accuracy: 0.3293 - val_loss: 2.6561 - val_accuracy: 0.2371

Epoch 00042: val_loss did not improve from 2.17904
Epoch 43/100
11442/11442 - 8s - loss: 2.0800 - accuracy: 0.3286 - val_loss: 2.4849 - val_accuracy: 0.2661

Epoch 00043: val_loss did not improve from 2.17904
Epoch 44/100
11442/11442 - 8s - loss: 2.0899 - accuracy: 0.3268 - val_loss: 2.6240 - val_accuracy: 0.2256

Epoch 00044: val_loss did not improve from 2.17904
Epoch 45/100
11442/11442 - 8s - loss: 2.0804 - accuracy: 0.3267 - val_loss: 2.4736 - val_accuracy: 0.2923

Epoch 00045: val_loss did not improve from 2.17904
Epoch 46/100
11442/11442 - 8s - loss: 2.0779 - accuracy: 0.3279 - val_loss: 2.4139 - val_accuracy: 0.2669

Epoch 00046: val_loss did not improve from 2.17904
Epoch 47/100
11442/11442 - 8s - loss: 2.0866 - accuracy: 0.3279 - val_loss: 2.4024 - val_accuracy: 0.2218

Epoch 00047: val_loss did not improve from 2.17904
Epoch 48/100
11442/11442 - 8s - loss: 2.0815 - accuracy: 0.3310 - val_loss: 2.5165 - val_accuracy: 0.2443

Epoch 00048: val_loss did not improve from 2.17904
Epoch 49/100
11442/11442 - 8s - loss: 2.0747 - accuracy: 0.3300 - val_loss: 2.4087 - val_accuracy: 0.2275

Epoch 00049: val_loss did not improve from 2.17904
Epoch 50/100
11442/11442 - 8s - loss: 2.0786 - accuracy: 0.3317 - val_loss: 2.3745 - val_accuracy: 0.2546

Epoch 00050: val_loss did not improve from 2.17904
Epoch 51/100
11442/11442 - 8s - loss: 2.0865 - accuracy: 0.3304 - val_loss: 2.2919 - val_accuracy: 0.2481

Epoch 00051: val_loss did not improve from 2.17904
Epoch 52/100
11442/11442 - 8s - loss: 2.0712 - accuracy: 0.3340 - val_loss: 2.4548 - val_accuracy: 0.2610

Epoch 00052: val_loss did not improve from 2.17904
Epoch 53/100
11442/11442 - 8s - loss: 2.0811 - accuracy: 0.3351 - val_loss: 2.7312 - val_accuracy: 0.2412

Epoch 00053: val_loss did not improve from 2.17904
Epoch 54/100
11442/11442 - 8s - loss: 2.0746 - accuracy: 0.3334 - val_loss: 2.3619 - val_accuracy: 0.2652

Epoch 00054: val_loss did not improve from 2.17904
Epoch 55/100
11442/11442 - 8s - loss: 2.0765 - accuracy: 0.3362 - val_loss: 2.4935 - val_accuracy: 0.2519

Epoch 00055: val_loss did not improve from 2.17904
Epoch 56/100
11442/11442 - 8s - loss: 2.0728 - accuracy: 0.3365 - val_loss: 2.4451 - val_accuracy: 0.2588

Epoch 00056: val_loss did not improve from 2.17904
Epoch 57/100
11442/11442 - 8s - loss: 2.0693 - accuracy: 0.3358 - val_loss: 2.3312 - val_accuracy: 0.2583

Epoch 00057: val_loss did not improve from 2.17904
Epoch 58/100
11442/11442 - 8s - loss: 2.0779 - accuracy: 0.3370 - val_loss: 2.5743 - val_accuracy: 0.2332

Epoch 00058: val_loss did not improve from 2.17904
Epoch 59/100
11442/11442 - 8s - loss: 2.0773 - accuracy: 0.3357 - val_loss: 2.4328 - val_accuracy: 0.2582

Epoch 00059: val_loss did not improve from 2.17904
Epoch 60/100
11442/11442 - 8s - loss: 2.0802 - accuracy: 0.3356 - val_loss: 2.3734 - val_accuracy: 0.2522

Epoch 00060: val_loss did not improve from 2.17904
Epoch 61/100
11442/11442 - 8s - loss: 2.0749 - accuracy: 0.3380 - val_loss: 2.4712 - val_accuracy: 0.2669

Epoch 00061: val_loss did not improve from 2.17904
Epoch 62/100
11442/11442 - 8s - loss: 2.0871 - accuracy: 0.3405 - val_loss: 2.5389 - val_accuracy: 0.2590

Epoch 00062: val_loss did not improve from 2.17904
Epoch 63/100
11442/11442 - 8s - loss: 2.0808 - accuracy: 0.3378 - val_loss: 2.6380 - val_accuracy: 0.2780

Epoch 00063: val_loss did not improve from 2.17904
Epoch 64/100
11442/11442 - 8s - loss: 2.1017 - accuracy: 0.3392 - val_loss: 2.6150 - val_accuracy: 0.2365

Epoch 00064: val_loss did not improve from 2.17904
Epoch 65/100
11442/11442 - 8s - loss: 2.1022 - accuracy: 0.3354 - val_loss: 2.7326 - val_accuracy: 0.2142

Epoch 00065: val_loss did not improve from 2.17904
Epoch 66/100
11442/11442 - 8s - loss: 2.0961 - accuracy: 0.3375 - val_loss: 2.5086 - val_accuracy: 0.2792

Epoch 00066: val_loss did not improve from 2.17904
Epoch 67/100
11442/11442 - 8s - loss: 2.0830 - accuracy: 0.3403 - val_loss: 2.4849 - val_accuracy: 0.2327

Epoch 00067: val_loss did not improve from 2.17904
Epoch 68/100
11442/11442 - 8s - loss: 2.0841 - accuracy: 0.3373 - val_loss: 2.5852 - val_accuracy: 0.2382

Epoch 00068: val_loss did not improve from 2.17904
Epoch 69/100
11442/11442 - 8s - loss: 2.0956 - accuracy: 0.3422 - val_loss: 2.5244 - val_accuracy: 0.2523

Epoch 00069: val_loss did not improve from 2.17904
Epoch 70/100
11442/11442 - 8s - loss: 2.0699 - accuracy: 0.3437 - val_loss: 2.6852 - val_accuracy: 0.2780

Epoch 00070: val_loss did not improve from 2.17904
Epoch 71/100
11442/11442 - 8s - loss: 2.0824 - accuracy: 0.3413 - val_loss: 2.3950 - val_accuracy: 0.2643

Epoch 00071: val_loss did not improve from 2.17904
Epoch 72/100
11442/11442 - 8s - loss: 2.0987 - accuracy: 0.3417 - val_loss: 2.5074 - val_accuracy: 0.2779

Epoch 00072: val_loss did not improve from 2.17904
Epoch 73/100
11442/11442 - 8s - loss: 2.0916 - accuracy: 0.3435 - val_loss: 2.5767 - val_accuracy: 0.2581

Epoch 00073: val_loss did not improve from 2.17904
Epoch 74/100
11442/11442 - 8s - loss: 2.0762 - accuracy: 0.3434 - val_loss: 2.4651 - val_accuracy: 0.2327

Epoch 00074: val_loss did not improve from 2.17904
Epoch 75/100
11442/11442 - 8s - loss: 2.0760 - accuracy: 0.3441 - val_loss: 2.6421 - val_accuracy: 0.2056

Epoch 00075: val_loss did not improve from 2.17904
Epoch 76/100
11442/11442 - 8s - loss: 2.0603 - accuracy: 0.3446 - val_loss: 2.5193 - val_accuracy: 0.2307

Epoch 00076: val_loss did not improve from 2.17904
Epoch 77/100
11442/11442 - 8s - loss: 2.0797 - accuracy: 0.3442 - val_loss: 2.6293 - val_accuracy: 0.2662

Epoch 00077: val_loss did not improve from 2.17904
Epoch 78/100
11442/11442 - 8s - loss: 2.0801 - accuracy: 0.3442 - val_loss: 2.5520 - val_accuracy: 0.2288

Epoch 00078: val_loss did not improve from 2.17904
Epoch 79/100
11442/11442 - 8s - loss: 2.0920 - accuracy: 0.3431 - val_loss: 2.4560 - val_accuracy: 0.2782

Epoch 00079: val_loss did not improve from 2.17904
Epoch 80/100
11442/11442 - 8s - loss: 2.0786 - accuracy: 0.3462 - val_loss: 2.5084 - val_accuracy: 0.2851

Epoch 00080: val_loss did not improve from 2.17904
Epoch 81/100
11442/11442 - 8s - loss: 2.0706 - accuracy: 0.3474 - val_loss: 2.5199 - val_accuracy: 0.2571

Epoch 00081: val_loss did not improve from 2.17904
Epoch 82/100
11442/11442 - 8s - loss: 2.0929 - accuracy: 0.3440 - val_loss: 2.6083 - val_accuracy: 0.2248

Epoch 00082: val_loss did not improve from 2.17904
Epoch 83/100
11442/11442 - 8s - loss: 2.0956 - accuracy: 0.3447 - val_loss: 2.5413 - val_accuracy: 0.2687

Epoch 00083: val_loss did not improve from 2.17904
Epoch 84/100
11442/11442 - 8s - loss: 2.0963 - accuracy: 0.3472 - val_loss: 2.5454 - val_accuracy: 0.2714

Epoch 00084: val_loss did not improve from 2.17904
Epoch 85/100
11442/11442 - 8s - loss: 2.0988 - accuracy: 0.3474 - val_loss: 2.6941 - val_accuracy: 0.2326

Epoch 00085: val_loss did not improve from 2.17904
Epoch 86/100
11442/11442 - 8s - loss: 2.0850 - accuracy: 0.3493 - val_loss: 2.4638 - val_accuracy: 0.2790

Epoch 00086: val_loss did not improve from 2.17904
Epoch 87/100
11442/11442 - 8s - loss: 2.0826 - accuracy: 0.3494 - val_loss: 2.5607 - val_accuracy: 0.2802

Epoch 00087: val_loss did not improve from 2.17904
Epoch 88/100
11442/11442 - 8s - loss: 2.0996 - accuracy: 0.3453 - val_loss: 2.6671 - val_accuracy: 0.2615

Epoch 00088: val_loss did not improve from 2.17904
Epoch 89/100
11442/11442 - 8s - loss: 2.1090 - accuracy: 0.3455 - val_loss: 2.6067 - val_accuracy: 0.3054

Epoch 00089: val_loss did not improve from 2.17904
Epoch 90/100
11442/11442 - 8s - loss: 2.0785 - accuracy: 0.3490 - val_loss: 2.4869 - val_accuracy: 0.2808

Epoch 00090: val_loss did not improve from 2.17904
Epoch 91/100
11442/11442 - 8s - loss: 2.0701 - accuracy: 0.3488 - val_loss: 2.7214 - val_accuracy: 0.2449

Epoch 00091: val_loss did not improve from 2.17904
Epoch 92/100
11442/11442 - 8s - loss: 2.0933 - accuracy: 0.3493 - val_loss: 2.5638 - val_accuracy: 0.2845

Epoch 00092: val_loss did not improve from 2.17904
Epoch 93/100
11442/11442 - 8s - loss: 2.0871 - accuracy: 0.3485 - val_loss: 2.4272 - val_accuracy: 0.2975

Epoch 00093: val_loss did not improve from 2.17904
Epoch 94/100
11442/11442 - 8s - loss: 2.0847 - accuracy: 0.3497 - val_loss: 2.6389 - val_accuracy: 0.2615

Epoch 00094: val_loss did not improve from 2.17904
Epoch 95/100
11442/11442 - 8s - loss: 2.0937 - accuracy: 0.3514 - val_loss: 2.8254 - val_accuracy: 0.2687

Epoch 00095: val_loss did not improve from 2.17904
Epoch 96/100
11442/11442 - 8s - loss: 2.0825 - accuracy: 0.3475 - val_loss: 2.6246 - val_accuracy: 0.2598

Epoch 00096: val_loss did not improve from 2.17904
Epoch 97/100
11442/11442 - 8s - loss: 2.0840 - accuracy: 0.3517 - val_loss: 2.4969 - val_accuracy: 0.2904

Epoch 00097: val_loss did not improve from 2.17904
Epoch 98/100
11442/11442 - 8s - loss: 2.0953 - accuracy: 0.3510 - val_loss: 2.5674 - val_accuracy: 0.2853

Epoch 00098: val_loss did not improve from 2.17904
Epoch 99/100
11442/11442 - 8s - loss: 2.0783 - accuracy: 0.3485 - val_loss: 2.6639 - val_accuracy: 0.2554

Epoch 00099: val_loss did not improve from 2.17904
Epoch 100/100
11442/11442 - 8s - loss: 2.1003 - accuracy: 0.3498 - val_loss: 2.8945 - val_accuracy: 0.2503

Epoch 00100: val_loss did not improve from 2.17904
