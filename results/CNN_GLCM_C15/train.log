Before oversampling: Counter({92.0: 7628, 100.0: 7624, 91.0: 7615, 0.0: 7615, 60.0: 7609, 10.0: 7595, 70.0: 7583, 1.0: 7580, 2.0: 7577, 20.0: 7519, 40.0: 7516, 50.0: 7476, 30.0: 7448, 90.0: 7439, 80.0: 7188})
After oversampling: Counter({100.0: 7628, 92.0: 7628, 91.0: 7628, 90.0: 7628, 20.0: 7628, 1.0: 7628, 80.0: 7628, 70.0: 7628, 0.0: 7628, 50.0: 7628, 30.0: 7628, 10.0: 7628, 40.0: 7628, 2.0: 7628, 60.0: 7628})
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
conv (InputLayer)               [(None, 23, 1)]      0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 23, 64)       384         conv[0][0]                       
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 23, 64)       20544       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 23, 64)       20544       conv1d_1[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1472)         0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 22)           32406       flatten[0][0]                    
__________________________________________________________________________________________________
cat (InputLayer)                [(None, 0)]          0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 15)           345         dense[0][0]                      
==================================================================================================
Total params: 74,223
Trainable params: 74,223
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
11442/11442 - 10s - loss: 2.0068 - accuracy: 0.2920 - val_loss: 2.1505 - val_accuracy: 0.2463

Epoch 00001: val_loss improved from inf to 2.15050, saving model to ./results/CNN_GLCM_C15/cp.ckpt
Epoch 2/100
11442/11442 - 10s - loss: 1.8329 - accuracy: 0.3608 - val_loss: 2.1994 - val_accuracy: 0.2631

Epoch 00002: val_loss did not improve from 2.15050
Epoch 3/100
11442/11442 - 10s - loss: 1.7898 - accuracy: 0.3752 - val_loss: 2.0859 - val_accuracy: 0.2711

Epoch 00003: val_loss improved from 2.15050 to 2.08586, saving model to ./results/CNN_GLCM_C15/cp.ckpt
Epoch 4/100
11442/11442 - 10s - loss: 1.7645 - accuracy: 0.3867 - val_loss: 2.2131 - val_accuracy: 0.2521

Epoch 00004: val_loss did not improve from 2.08586
Epoch 5/100
11442/11442 - 10s - loss: 1.7460 - accuracy: 0.3952 - val_loss: 2.1389 - val_accuracy: 0.2868

Epoch 00005: val_loss did not improve from 2.08586
Epoch 6/100
11442/11442 - 10s - loss: 1.7284 - accuracy: 0.3996 - val_loss: 2.1509 - val_accuracy: 0.2709

Epoch 00006: val_loss did not improve from 2.08586
Epoch 7/100
11442/11442 - 10s - loss: 1.7142 - accuracy: 0.4040 - val_loss: 2.1257 - val_accuracy: 0.2966

Epoch 00007: val_loss did not improve from 2.08586
Epoch 8/100
11442/11442 - 10s - loss: 1.7031 - accuracy: 0.4092 - val_loss: 2.1960 - val_accuracy: 0.2644

Epoch 00008: val_loss did not improve from 2.08586
Epoch 9/100
11442/11442 - 10s - loss: 1.6913 - accuracy: 0.4136 - val_loss: 2.1666 - val_accuracy: 0.2751

Epoch 00009: val_loss did not improve from 2.08586
Epoch 10/100
11442/11442 - 10s - loss: 1.6799 - accuracy: 0.4178 - val_loss: 2.2338 - val_accuracy: 0.2695

Epoch 00010: val_loss did not improve from 2.08586
Epoch 11/100
11442/11442 - 10s - loss: 1.6710 - accuracy: 0.4192 - val_loss: 2.1937 - val_accuracy: 0.2618

Epoch 00011: val_loss did not improve from 2.08586
Epoch 12/100
11442/11442 - 10s - loss: 1.6622 - accuracy: 0.4232 - val_loss: 2.2031 - val_accuracy: 0.2913

Epoch 00012: val_loss did not improve from 2.08586
Epoch 13/100
11442/11442 - 11s - loss: 1.6564 - accuracy: 0.4257 - val_loss: 2.1764 - val_accuracy: 0.2845

Epoch 00013: val_loss did not improve from 2.08586
Epoch 14/100
11442/11442 - 10s - loss: 1.6493 - accuracy: 0.4259 - val_loss: 2.2240 - val_accuracy: 0.2838

Epoch 00014: val_loss did not improve from 2.08586
Epoch 15/100
11442/11442 - 10s - loss: 1.6451 - accuracy: 0.4305 - val_loss: 2.2466 - val_accuracy: 0.2816

Epoch 00015: val_loss did not improve from 2.08586
Epoch 16/100
11442/11442 - 10s - loss: 1.6380 - accuracy: 0.4304 - val_loss: 2.2273 - val_accuracy: 0.2683

Epoch 00016: val_loss did not improve from 2.08586
Epoch 17/100
11442/11442 - 10s - loss: 1.6350 - accuracy: 0.4332 - val_loss: 2.2314 - val_accuracy: 0.2801

Epoch 00017: val_loss did not improve from 2.08586
Epoch 18/100
11442/11442 - 10s - loss: 1.6284 - accuracy: 0.4355 - val_loss: 2.2789 - val_accuracy: 0.2850

Epoch 00018: val_loss did not improve from 2.08586
Epoch 19/100
11442/11442 - 10s - loss: 1.6238 - accuracy: 0.4385 - val_loss: 2.1993 - val_accuracy: 0.2859

Epoch 00019: val_loss did not improve from 2.08586
Epoch 20/100
11442/11442 - 10s - loss: 1.6194 - accuracy: 0.4394 - val_loss: 2.2254 - val_accuracy: 0.2879

Epoch 00020: val_loss did not improve from 2.08586
Epoch 21/100
11442/11442 - 10s - loss: 1.6160 - accuracy: 0.4394 - val_loss: 2.2583 - val_accuracy: 0.2801

Epoch 00021: val_loss did not improve from 2.08586
Epoch 22/100
11442/11442 - 10s - loss: 1.6122 - accuracy: 0.4406 - val_loss: 2.2780 - val_accuracy: 0.2745

Epoch 00022: val_loss did not improve from 2.08586
Epoch 23/100
11442/11442 - 10s - loss: 1.6062 - accuracy: 0.4442 - val_loss: 2.3403 - val_accuracy: 0.2667

Epoch 00023: val_loss did not improve from 2.08586
Epoch 24/100
11442/11442 - 10s - loss: 1.6046 - accuracy: 0.4443 - val_loss: 2.2678 - val_accuracy: 0.2868

Epoch 00024: val_loss did not improve from 2.08586
Epoch 25/100
11442/11442 - 10s - loss: 1.6012 - accuracy: 0.4448 - val_loss: 2.2683 - val_accuracy: 0.2827

Epoch 00025: val_loss did not improve from 2.08586
Epoch 26/100
11442/11442 - 10s - loss: 1.5992 - accuracy: 0.4464 - val_loss: 2.3451 - val_accuracy: 0.2852

Epoch 00026: val_loss did not improve from 2.08586
Epoch 27/100
11442/11442 - 10s - loss: 1.5953 - accuracy: 0.4467 - val_loss: 2.4041 - val_accuracy: 0.2859

Epoch 00027: val_loss did not improve from 2.08586
Epoch 28/100
11442/11442 - 10s - loss: 1.5923 - accuracy: 0.4484 - val_loss: 2.2878 - val_accuracy: 0.2774

Epoch 00028: val_loss did not improve from 2.08586
Epoch 29/100
11442/11442 - 10s - loss: 1.5916 - accuracy: 0.4484 - val_loss: 2.3089 - val_accuracy: 0.2821

Epoch 00029: val_loss did not improve from 2.08586
Epoch 30/100
11442/11442 - 10s - loss: 1.5890 - accuracy: 0.4503 - val_loss: 2.3342 - val_accuracy: 0.2914

Epoch 00030: val_loss did not improve from 2.08586
Epoch 31/100
11442/11442 - 10s - loss: 1.5855 - accuracy: 0.4488 - val_loss: 2.3168 - val_accuracy: 0.2886

Epoch 00031: val_loss did not improve from 2.08586
Epoch 32/100
11442/11442 - 10s - loss: 1.5833 - accuracy: 0.4537 - val_loss: 2.3593 - val_accuracy: 0.2712

Epoch 00032: val_loss did not improve from 2.08586
Epoch 33/100
11442/11442 - 11s - loss: 1.5799 - accuracy: 0.4523 - val_loss: 2.3801 - val_accuracy: 0.2710

Epoch 00033: val_loss did not improve from 2.08586
Epoch 34/100
11442/11442 - 12s - loss: 1.5774 - accuracy: 0.4541 - val_loss: 2.2852 - val_accuracy: 0.2775

Epoch 00034: val_loss did not improve from 2.08586
Epoch 35/100
11442/11442 - 11s - loss: 1.5749 - accuracy: 0.4519 - val_loss: 2.3704 - val_accuracy: 0.2845

Epoch 00035: val_loss did not improve from 2.08586
Epoch 36/100
11442/11442 - 11s - loss: 1.5735 - accuracy: 0.4546 - val_loss: 2.3497 - val_accuracy: 0.2868

Epoch 00036: val_loss did not improve from 2.08586
Epoch 37/100
11442/11442 - 11s - loss: 1.5712 - accuracy: 0.4549 - val_loss: 2.3286 - val_accuracy: 0.2841

Epoch 00037: val_loss did not improve from 2.08586
Epoch 38/100
11442/11442 - 11s - loss: 1.5693 - accuracy: 0.4555 - val_loss: 2.3706 - val_accuracy: 0.2810

Epoch 00038: val_loss did not improve from 2.08586
Epoch 39/100
11442/11442 - 11s - loss: 1.5676 - accuracy: 0.4564 - val_loss: 2.4179 - val_accuracy: 0.2748

Epoch 00039: val_loss did not improve from 2.08586
Epoch 40/100
11442/11442 - 11s - loss: 1.5636 - accuracy: 0.4578 - val_loss: 2.3354 - val_accuracy: 0.2803

Epoch 00040: val_loss did not improve from 2.08586
Epoch 41/100
11442/11442 - 11s - loss: 1.5624 - accuracy: 0.4571 - val_loss: 2.3757 - val_accuracy: 0.2727

Epoch 00041: val_loss did not improve from 2.08586
Epoch 42/100
11442/11442 - 11s - loss: 1.5604 - accuracy: 0.4591 - val_loss: 2.4428 - val_accuracy: 0.2804

Epoch 00042: val_loss did not improve from 2.08586
Epoch 43/100
11442/11442 - 11s - loss: 1.5552 - accuracy: 0.4601 - val_loss: 2.4588 - val_accuracy: 0.2788

Epoch 00043: val_loss did not improve from 2.08586
Epoch 44/100
11442/11442 - 11s - loss: 1.5561 - accuracy: 0.4582 - val_loss: 2.3798 - val_accuracy: 0.2842

Epoch 00044: val_loss did not improve from 2.08586
Epoch 45/100
11442/11442 - 10s - loss: 1.5544 - accuracy: 0.4635 - val_loss: 2.3326 - val_accuracy: 0.2899

Epoch 00045: val_loss did not improve from 2.08586
Epoch 46/100
11442/11442 - 10s - loss: 1.5519 - accuracy: 0.4612 - val_loss: 2.4096 - val_accuracy: 0.2713

Epoch 00046: val_loss did not improve from 2.08586
Epoch 47/100
11442/11442 - 10s - loss: 1.5525 - accuracy: 0.4614 - val_loss: 2.4192 - val_accuracy: 0.2796

Epoch 00047: val_loss did not improve from 2.08586
Epoch 48/100
11442/11442 - 10s - loss: 1.5500 - accuracy: 0.4608 - val_loss: 2.4040 - val_accuracy: 0.2734

Epoch 00048: val_loss did not improve from 2.08586
Epoch 49/100
11442/11442 - 10s - loss: 1.5492 - accuracy: 0.4619 - val_loss: 2.3874 - val_accuracy: 0.2968

Epoch 00049: val_loss did not improve from 2.08586
Epoch 50/100
11442/11442 - 10s - loss: 1.5451 - accuracy: 0.4636 - val_loss: 2.3838 - val_accuracy: 0.2865

Epoch 00050: val_loss did not improve from 2.08586
Epoch 51/100
11442/11442 - 10s - loss: 1.5411 - accuracy: 0.4655 - val_loss: 2.4768 - val_accuracy: 0.2890

Epoch 00051: val_loss did not improve from 2.08586
Epoch 52/100
11442/11442 - 10s - loss: 1.5425 - accuracy: 0.4637 - val_loss: 2.4824 - val_accuracy: 0.2715

Epoch 00052: val_loss did not improve from 2.08586
Epoch 53/100
11442/11442 - 10s - loss: 1.5385 - accuracy: 0.4656 - val_loss: 2.3803 - val_accuracy: 0.2826

Epoch 00053: val_loss did not improve from 2.08586
Epoch 54/100
11442/11442 - 10s - loss: 1.5376 - accuracy: 0.4662 - val_loss: 2.4465 - val_accuracy: 0.2902

Epoch 00054: val_loss did not improve from 2.08586
Epoch 55/100
11442/11442 - 10s - loss: 1.5347 - accuracy: 0.4661 - val_loss: 2.4022 - val_accuracy: 0.2865

Epoch 00055: val_loss did not improve from 2.08586
Epoch 56/100
11442/11442 - 10s - loss: 1.5357 - accuracy: 0.4677 - val_loss: 2.4243 - val_accuracy: 0.2943

Epoch 00056: val_loss did not improve from 2.08586
Epoch 57/100
11442/11442 - 10s - loss: 1.5344 - accuracy: 0.4683 - val_loss: 2.3961 - val_accuracy: 0.2769

Epoch 00057: val_loss did not improve from 2.08586
Epoch 58/100
11442/11442 - 10s - loss: 1.5319 - accuracy: 0.4664 - val_loss: 2.4521 - val_accuracy: 0.2838

Epoch 00058: val_loss did not improve from 2.08586
Epoch 59/100
11442/11442 - 10s - loss: 1.5313 - accuracy: 0.4690 - val_loss: 2.4273 - val_accuracy: 0.2795

Epoch 00059: val_loss did not improve from 2.08586
Epoch 60/100
11442/11442 - 10s - loss: 1.5282 - accuracy: 0.4691 - val_loss: 2.4416 - val_accuracy: 0.2808

Epoch 00060: val_loss did not improve from 2.08586
Epoch 61/100
11442/11442 - 10s - loss: 1.5278 - accuracy: 0.4696 - val_loss: 2.4756 - val_accuracy: 0.2808

Epoch 00061: val_loss did not improve from 2.08586
Epoch 62/100
11442/11442 - 11s - loss: 1.5278 - accuracy: 0.4682 - val_loss: 2.4621 - val_accuracy: 0.2847

Epoch 00062: val_loss did not improve from 2.08586
Epoch 63/100
11442/11442 - 11s - loss: 1.5241 - accuracy: 0.4691 - val_loss: 2.4384 - val_accuracy: 0.2817

Epoch 00063: val_loss did not improve from 2.08586
Epoch 64/100
11442/11442 - 11s - loss: 1.5240 - accuracy: 0.4694 - val_loss: 2.4712 - val_accuracy: 0.2839

Epoch 00064: val_loss did not improve from 2.08586
Epoch 65/100
11442/11442 - 11s - loss: 1.5238 - accuracy: 0.4710 - val_loss: 2.4679 - val_accuracy: 0.2744

Epoch 00065: val_loss did not improve from 2.08586
Epoch 66/100
11442/11442 - 12s - loss: 1.5202 - accuracy: 0.4701 - val_loss: 2.4872 - val_accuracy: 0.2767

Epoch 00066: val_loss did not improve from 2.08586
Epoch 67/100
11442/11442 - 11s - loss: 1.5196 - accuracy: 0.4723 - val_loss: 2.5090 - val_accuracy: 0.2749

Epoch 00067: val_loss did not improve from 2.08586
Epoch 68/100
11442/11442 - 11s - loss: 1.5183 - accuracy: 0.4726 - val_loss: 2.5013 - val_accuracy: 0.2812

Epoch 00068: val_loss did not improve from 2.08586
Epoch 69/100
11442/11442 - 11s - loss: 1.5191 - accuracy: 0.4722 - val_loss: 2.4902 - val_accuracy: 0.2734

Epoch 00069: val_loss did not improve from 2.08586
Epoch 70/100
11442/11442 - 11s - loss: 1.5177 - accuracy: 0.4718 - val_loss: 2.4744 - val_accuracy: 0.2831

Epoch 00070: val_loss did not improve from 2.08586
Epoch 71/100
11442/11442 - 11s - loss: 1.5145 - accuracy: 0.4745 - val_loss: 2.4319 - val_accuracy: 0.2776

Epoch 00071: val_loss did not improve from 2.08586
Epoch 72/100
11442/11442 - 11s - loss: 1.5144 - accuracy: 0.4747 - val_loss: 2.4734 - val_accuracy: 0.2762

Epoch 00072: val_loss did not improve from 2.08586
Epoch 73/100
11442/11442 - 10s - loss: 1.5116 - accuracy: 0.4734 - val_loss: 2.4812 - val_accuracy: 0.2865

Epoch 00073: val_loss did not improve from 2.08586
Epoch 74/100
11442/11442 - 10s - loss: 1.5130 - accuracy: 0.4743 - val_loss: 2.5081 - val_accuracy: 0.2847

Epoch 00074: val_loss did not improve from 2.08586
Epoch 75/100
11442/11442 - 10s - loss: 1.5084 - accuracy: 0.4734 - val_loss: 2.5719 - val_accuracy: 0.2792

Epoch 00075: val_loss did not improve from 2.08586
Epoch 76/100
11442/11442 - 10s - loss: 1.5090 - accuracy: 0.4749 - val_loss: 2.4942 - val_accuracy: 0.2756

Epoch 00076: val_loss did not improve from 2.08586
Epoch 77/100
11442/11442 - 10s - loss: 1.5079 - accuracy: 0.4751 - val_loss: 2.4966 - val_accuracy: 0.2753

Epoch 00077: val_loss did not improve from 2.08586
Epoch 78/100
11442/11442 - 10s - loss: 1.5080 - accuracy: 0.4754 - val_loss: 2.4912 - val_accuracy: 0.2824

Epoch 00078: val_loss did not improve from 2.08586
Epoch 79/100
11442/11442 - 10s - loss: 1.5068 - accuracy: 0.4767 - val_loss: 2.5244 - val_accuracy: 0.2683

Epoch 00079: val_loss did not improve from 2.08586
Epoch 80/100
11442/11442 - 10s - loss: 1.5044 - accuracy: 0.4759 - val_loss: 2.6447 - val_accuracy: 0.2756

Epoch 00080: val_loss did not improve from 2.08586
Epoch 81/100
11442/11442 - 10s - loss: 1.5022 - accuracy: 0.4775 - val_loss: 2.4951 - val_accuracy: 0.2803

Epoch 00081: val_loss did not improve from 2.08586
Epoch 82/100
11442/11442 - 10s - loss: 1.5030 - accuracy: 0.4776 - val_loss: 2.5379 - val_accuracy: 0.2817

Epoch 00082: val_loss did not improve from 2.08586
Epoch 83/100
11442/11442 - 10s - loss: 1.5033 - accuracy: 0.4780 - val_loss: 2.4743 - val_accuracy: 0.2832

Epoch 00083: val_loss did not improve from 2.08586
Epoch 84/100
11442/11442 - 10s - loss: 1.5001 - accuracy: 0.4792 - val_loss: 2.5781 - val_accuracy: 0.2823

Epoch 00084: val_loss did not improve from 2.08586
Epoch 85/100
11442/11442 - 10s - loss: 1.5003 - accuracy: 0.4774 - val_loss: 2.5312 - val_accuracy: 0.2862

Epoch 00085: val_loss did not improve from 2.08586
Epoch 86/100
11442/11442 - 10s - loss: 1.4987 - accuracy: 0.4792 - val_loss: 2.6034 - val_accuracy: 0.2827

Epoch 00086: val_loss did not improve from 2.08586
Epoch 87/100
11442/11442 - 10s - loss: 1.4970 - accuracy: 0.4811 - val_loss: 2.6500 - val_accuracy: 0.2816

Epoch 00087: val_loss did not improve from 2.08586
Epoch 88/100
11442/11442 - 10s - loss: 1.4965 - accuracy: 0.4801 - val_loss: 2.5547 - val_accuracy: 0.2741

Epoch 00088: val_loss did not improve from 2.08586
Epoch 89/100
11442/11442 - 10s - loss: 1.4946 - accuracy: 0.4806 - val_loss: 2.5929 - val_accuracy: 0.2819

Epoch 00089: val_loss did not improve from 2.08586
Epoch 90/100
11442/11442 - 10s - loss: 1.4938 - accuracy: 0.4822 - val_loss: 2.5704 - val_accuracy: 0.2767

Epoch 00090: val_loss did not improve from 2.08586
Epoch 91/100
11442/11442 - 10s - loss: 1.4945 - accuracy: 0.4787 - val_loss: 2.5185 - val_accuracy: 0.2845

Epoch 00091: val_loss did not improve from 2.08586
Epoch 92/100
11442/11442 - 10s - loss: 1.4921 - accuracy: 0.4795 - val_loss: 2.5623 - val_accuracy: 0.2842

Epoch 00092: val_loss did not improve from 2.08586
Epoch 93/100
11442/11442 - 10s - loss: 1.4931 - accuracy: 0.4814 - val_loss: 2.6331 - val_accuracy: 0.2818

Epoch 00093: val_loss did not improve from 2.08586
Epoch 94/100
11442/11442 - 10s - loss: 1.4937 - accuracy: 0.4791 - val_loss: 2.5636 - val_accuracy: 0.2813

Epoch 00094: val_loss did not improve from 2.08586
Epoch 95/100
11442/11442 - 10s - loss: 1.4909 - accuracy: 0.4819 - val_loss: 2.6027 - val_accuracy: 0.2774

Epoch 00095: val_loss did not improve from 2.08586
Epoch 96/100
11442/11442 - 10s - loss: 1.4916 - accuracy: 0.4792 - val_loss: 2.5370 - val_accuracy: 0.2799

Epoch 00096: val_loss did not improve from 2.08586
Epoch 97/100
11442/11442 - 10s - loss: 1.4883 - accuracy: 0.4825 - val_loss: 2.5699 - val_accuracy: 0.2736

Epoch 00097: val_loss did not improve from 2.08586
Epoch 98/100
11442/11442 - 10s - loss: 1.4907 - accuracy: 0.4836 - val_loss: 2.5737 - val_accuracy: 0.2769

Epoch 00098: val_loss did not improve from 2.08586
Epoch 99/100
11442/11442 - 10s - loss: 1.4873 - accuracy: 0.4827 - val_loss: 2.6244 - val_accuracy: 0.2805

Epoch 00099: val_loss did not improve from 2.08586
Epoch 100/100
11442/11442 - 10s - loss: 1.4856 - accuracy: 0.4856 - val_loss: 2.6173 - val_accuracy: 0.2807

Epoch 00100: val_loss did not improve from 2.08586
