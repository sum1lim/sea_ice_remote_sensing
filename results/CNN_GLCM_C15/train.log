Before oversampling: Counter({92.0: 7628, 100.0: 7624, 91.0: 7615, 0.0: 7615, 60.0: 7609, 10.0: 7595, 70.0: 7583, 1.0: 7580, 2.0: 7577, 20.0: 7519, 40.0: 7516, 50.0: 7476, 30.0: 7448, 90.0: 7439, 80.0: 7188})
After oversampling: Counter({100.0: 7628, 92.0: 7628, 91.0: 7628, 90.0: 7628, 20.0: 7628, 1.0: 7628, 80.0: 7628, 70.0: 7628, 0.0: 7628, 50.0: 7628, 30.0: 7628, 10.0: 7628, 40.0: 7628, 2.0: 7628, 60.0: 7628})
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
conv (InputLayer)               [(None, 21, 1)]      0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 21, 64)       256         conv[0][0]                       
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 21, 64)       12352       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 21, 64)       12352       conv1d_1[0][0]                   
__________________________________________________________________________________________________
cat (InputLayer)                [(None, 0)]          0                                            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1344)         0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 1344)         0           cat[0][0]                        
                                                                 flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 22)           29590       concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 15)           345         dense[0][0]                      
==================================================================================================
Total params: 54,895
Trainable params: 54,895
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
11442/11442 - 19s - loss: 1.9955 - accuracy: 0.2929 - val_loss: 2.1090 - val_accuracy: 0.2446

Epoch 00001: val_loss improved from inf to 2.10904, saving model to ./results/CNN_GLCM_C15/cp.ckpt
Epoch 2/100
11442/11442 - 19s - loss: 1.8378 - accuracy: 0.3546 - val_loss: 2.1288 - val_accuracy: 0.2619

Epoch 00002: val_loss did not improve from 2.10904
Epoch 3/100
11442/11442 - 21s - loss: 1.7919 - accuracy: 0.3740 - val_loss: 2.0985 - val_accuracy: 0.2565

Epoch 00003: val_loss improved from 2.10904 to 2.09852, saving model to ./results/CNN_GLCM_C15/cp.ckpt
Epoch 4/100
11442/11442 - 19s - loss: 1.7609 - accuracy: 0.3869 - val_loss: 2.1159 - val_accuracy: 0.2673

Epoch 00004: val_loss did not improve from 2.09852
Epoch 5/100
11442/11442 - 21s - loss: 1.7405 - accuracy: 0.3966 - val_loss: 2.1811 - val_accuracy: 0.2513

Epoch 00005: val_loss did not improve from 2.09852
Epoch 6/100
11442/11442 - 19s - loss: 1.7267 - accuracy: 0.4017 - val_loss: 2.1904 - val_accuracy: 0.2626

Epoch 00006: val_loss did not improve from 2.09852
Epoch 7/100
11442/11442 - 19s - loss: 1.7137 - accuracy: 0.4093 - val_loss: 2.1206 - val_accuracy: 0.2676

Epoch 00007: val_loss did not improve from 2.09852
Epoch 8/100
11442/11442 - 19s - loss: 1.7070 - accuracy: 0.4108 - val_loss: 2.1323 - val_accuracy: 0.2819

Epoch 00008: val_loss did not improve from 2.09852
Epoch 9/100
11442/11442 - 19s - loss: 1.6988 - accuracy: 0.4137 - val_loss: 2.1737 - val_accuracy: 0.2892

Epoch 00009: val_loss did not improve from 2.09852
Epoch 10/100
11442/11442 - 19s - loss: 1.6895 - accuracy: 0.4171 - val_loss: 2.1907 - val_accuracy: 0.2808

Epoch 00010: val_loss did not improve from 2.09852
Epoch 11/100
11442/11442 - 19s - loss: 1.6822 - accuracy: 0.4198 - val_loss: 2.2100 - val_accuracy: 0.2684

Epoch 00011: val_loss did not improve from 2.09852
Epoch 12/100
11442/11442 - 19s - loss: 1.6761 - accuracy: 0.4205 - val_loss: 2.1892 - val_accuracy: 0.2844

Epoch 00012: val_loss did not improve from 2.09852
Epoch 13/100
11442/11442 - 19s - loss: 1.6689 - accuracy: 0.4245 - val_loss: 2.1862 - val_accuracy: 0.2846

Epoch 00013: val_loss did not improve from 2.09852
Epoch 14/100
11442/11442 - 19s - loss: 1.6640 - accuracy: 0.4264 - val_loss: 2.2130 - val_accuracy: 0.2726

Epoch 00014: val_loss did not improve from 2.09852
Epoch 15/100
11442/11442 - 19s - loss: 1.6590 - accuracy: 0.4291 - val_loss: 2.1940 - val_accuracy: 0.2835

Epoch 00015: val_loss did not improve from 2.09852
Epoch 16/100
11442/11442 - 22s - loss: 1.6543 - accuracy: 0.4291 - val_loss: 2.2697 - val_accuracy: 0.2831

Epoch 00016: val_loss did not improve from 2.09852
Epoch 17/100
11442/11442 - 19s - loss: 1.6502 - accuracy: 0.4305 - val_loss: 2.1970 - val_accuracy: 0.2827

Epoch 00017: val_loss did not improve from 2.09852
Epoch 18/100
11442/11442 - 19s - loss: 1.6459 - accuracy: 0.4308 - val_loss: 2.2690 - val_accuracy: 0.2787

Epoch 00018: val_loss did not improve from 2.09852
Epoch 19/100
11442/11442 - 19s - loss: 1.6417 - accuracy: 0.4321 - val_loss: 2.2309 - val_accuracy: 0.2714

Epoch 00019: val_loss did not improve from 2.09852
Epoch 20/100
11442/11442 - 19s - loss: 1.6400 - accuracy: 0.4338 - val_loss: 2.2179 - val_accuracy: 0.2834

Epoch 00020: val_loss did not improve from 2.09852
Epoch 21/100
11442/11442 - 19s - loss: 1.6341 - accuracy: 0.4349 - val_loss: 2.2636 - val_accuracy: 0.2707

Epoch 00021: val_loss did not improve from 2.09852
Epoch 22/100
11442/11442 - 19s - loss: 1.6296 - accuracy: 0.4365 - val_loss: 2.2869 - val_accuracy: 0.2827

Epoch 00022: val_loss did not improve from 2.09852
Epoch 23/100
11442/11442 - 19s - loss: 1.6256 - accuracy: 0.4381 - val_loss: 2.2955 - val_accuracy: 0.2775

Epoch 00023: val_loss did not improve from 2.09852
Epoch 24/100
11442/11442 - 19s - loss: 1.6229 - accuracy: 0.4387 - val_loss: 2.3022 - val_accuracy: 0.2972

Epoch 00024: val_loss did not improve from 2.09852
Epoch 25/100
11442/11442 - 19s - loss: 1.6204 - accuracy: 0.4394 - val_loss: 2.2952 - val_accuracy: 0.2830

Epoch 00025: val_loss did not improve from 2.09852
Epoch 26/100
11442/11442 - 18s - loss: 1.6172 - accuracy: 0.4414 - val_loss: 2.2795 - val_accuracy: 0.2808

Epoch 00026: val_loss did not improve from 2.09852
Epoch 27/100
11442/11442 - 19s - loss: 1.6145 - accuracy: 0.4420 - val_loss: 2.2936 - val_accuracy: 0.2794

Epoch 00027: val_loss did not improve from 2.09852
Epoch 28/100
11442/11442 - 18s - loss: 1.6143 - accuracy: 0.4409 - val_loss: 2.2675 - val_accuracy: 0.2874

Epoch 00028: val_loss did not improve from 2.09852
Epoch 29/100
11442/11442 - 19s - loss: 1.6100 - accuracy: 0.4429 - val_loss: 2.2640 - val_accuracy: 0.2802

Epoch 00029: val_loss did not improve from 2.09852
Epoch 30/100
11442/11442 - 19s - loss: 1.6059 - accuracy: 0.4440 - val_loss: 2.3472 - val_accuracy: 0.2839

Epoch 00030: val_loss did not improve from 2.09852
Epoch 31/100
11442/11442 - 19s - loss: 1.6062 - accuracy: 0.4443 - val_loss: 2.3322 - val_accuracy: 0.2861

Epoch 00031: val_loss did not improve from 2.09852
Epoch 32/100
11442/11442 - 19s - loss: 1.6015 - accuracy: 0.4446 - val_loss: 2.2935 - val_accuracy: 0.2851

Epoch 00032: val_loss did not improve from 2.09852
Epoch 33/100
11442/11442 - 19s - loss: 1.6010 - accuracy: 0.4479 - val_loss: 2.3541 - val_accuracy: 0.2829

Epoch 00033: val_loss did not improve from 2.09852
Epoch 34/100
11442/11442 - 19s - loss: 1.5984 - accuracy: 0.4466 - val_loss: 2.3395 - val_accuracy: 0.2839

Epoch 00034: val_loss did not improve from 2.09852
Epoch 35/100
11442/11442 - 19s - loss: 1.5973 - accuracy: 0.4480 - val_loss: 2.2940 - val_accuracy: 0.2922

Epoch 00035: val_loss did not improve from 2.09852
Epoch 36/100
11442/11442 - 19s - loss: 1.5962 - accuracy: 0.4454 - val_loss: 2.2849 - val_accuracy: 0.2846

Epoch 00036: val_loss did not improve from 2.09852
Epoch 37/100
11442/11442 - 19s - loss: 1.5903 - accuracy: 0.4482 - val_loss: 2.3432 - val_accuracy: 0.2910

Epoch 00037: val_loss did not improve from 2.09852
Epoch 38/100
11442/11442 - 19s - loss: 1.5917 - accuracy: 0.4498 - val_loss: 2.2990 - val_accuracy: 0.2814

Epoch 00038: val_loss did not improve from 2.09852
Epoch 39/100
11442/11442 - 19s - loss: 1.5919 - accuracy: 0.4511 - val_loss: 2.3273 - val_accuracy: 0.2868

Epoch 00039: val_loss did not improve from 2.09852
Epoch 40/100
11442/11442 - 18s - loss: 1.5891 - accuracy: 0.4503 - val_loss: 2.3182 - val_accuracy: 0.2746

Epoch 00040: val_loss did not improve from 2.09852
Epoch 41/100
11442/11442 - 19s - loss: 1.5843 - accuracy: 0.4512 - val_loss: 2.2980 - val_accuracy: 0.2863

Epoch 00041: val_loss did not improve from 2.09852
Epoch 42/100
11442/11442 - 19s - loss: 1.5839 - accuracy: 0.4517 - val_loss: 2.3762 - val_accuracy: 0.2784

Epoch 00042: val_loss did not improve from 2.09852
Epoch 43/100
11442/11442 - 19s - loss: 1.5817 - accuracy: 0.4510 - val_loss: 2.4083 - val_accuracy: 0.2789

Epoch 00043: val_loss did not improve from 2.09852
Epoch 44/100
11442/11442 - 19s - loss: 1.5816 - accuracy: 0.4529 - val_loss: 2.3822 - val_accuracy: 0.2735

Epoch 00044: val_loss did not improve from 2.09852
Epoch 45/100
11442/11442 - 18s - loss: 1.5801 - accuracy: 0.4535 - val_loss: 2.3516 - val_accuracy: 0.2842

Epoch 00045: val_loss did not improve from 2.09852
Epoch 46/100
11442/11442 - 18s - loss: 1.5772 - accuracy: 0.4545 - val_loss: 2.3961 - val_accuracy: 0.2823

Epoch 00046: val_loss did not improve from 2.09852
Epoch 47/100
11442/11442 - 19s - loss: 1.5760 - accuracy: 0.4560 - val_loss: 2.3339 - val_accuracy: 0.2840

Epoch 00047: val_loss did not improve from 2.09852
Epoch 48/100
11442/11442 - 19s - loss: 1.5748 - accuracy: 0.4561 - val_loss: 2.3679 - val_accuracy: 0.2885

Epoch 00048: val_loss did not improve from 2.09852
Epoch 49/100
11442/11442 - 18s - loss: 1.5754 - accuracy: 0.4543 - val_loss: 2.3651 - val_accuracy: 0.2834

Epoch 00049: val_loss did not improve from 2.09852
Epoch 50/100
11442/11442 - 18s - loss: 1.5744 - accuracy: 0.4539 - val_loss: 2.3790 - val_accuracy: 0.2686

Epoch 00050: val_loss did not improve from 2.09852
Epoch 51/100
11442/11442 - 18s - loss: 1.5740 - accuracy: 0.4567 - val_loss: 2.3749 - val_accuracy: 0.2847

Epoch 00051: val_loss did not improve from 2.09852
Epoch 52/100
11442/11442 - 19s - loss: 1.5685 - accuracy: 0.4577 - val_loss: 2.3180 - val_accuracy: 0.2739

Epoch 00052: val_loss did not improve from 2.09852
Epoch 53/100
11442/11442 - 19s - loss: 1.5686 - accuracy: 0.4571 - val_loss: 2.3614 - val_accuracy: 0.2723

Epoch 00053: val_loss did not improve from 2.09852
Epoch 54/100
11442/11442 - 18s - loss: 1.5678 - accuracy: 0.4574 - val_loss: 2.3734 - val_accuracy: 0.2611

Epoch 00054: val_loss did not improve from 2.09852
Epoch 55/100
11442/11442 - 19s - loss: 1.5665 - accuracy: 0.4569 - val_loss: 2.3872 - val_accuracy: 0.2866

Epoch 00055: val_loss did not improve from 2.09852
Epoch 56/100
11442/11442 - 19s - loss: 1.5644 - accuracy: 0.4591 - val_loss: 2.3677 - val_accuracy: 0.2722

Epoch 00056: val_loss did not improve from 2.09852
Epoch 57/100
11442/11442 - 18s - loss: 1.5654 - accuracy: 0.4586 - val_loss: 2.3836 - val_accuracy: 0.2864

Epoch 00057: val_loss did not improve from 2.09852
Epoch 58/100
11442/11442 - 19s - loss: 1.5622 - accuracy: 0.4602 - val_loss: 2.4453 - val_accuracy: 0.2813

Epoch 00058: val_loss did not improve from 2.09852
Epoch 59/100
11442/11442 - 18s - loss: 1.5620 - accuracy: 0.4594 - val_loss: 2.4517 - val_accuracy: 0.2806

Epoch 00059: val_loss did not improve from 2.09852
Epoch 60/100
11442/11442 - 18s - loss: 1.5613 - accuracy: 0.4576 - val_loss: 2.3676 - val_accuracy: 0.2709

Epoch 00060: val_loss did not improve from 2.09852
Epoch 61/100
11442/11442 - 18s - loss: 1.5594 - accuracy: 0.4609 - val_loss: 2.3917 - val_accuracy: 0.2799

Epoch 00061: val_loss did not improve from 2.09852
Epoch 62/100
11442/11442 - 18s - loss: 1.5582 - accuracy: 0.4611 - val_loss: 2.4236 - val_accuracy: 0.2791

Epoch 00062: val_loss did not improve from 2.09852
Epoch 63/100
11442/11442 - 19s - loss: 1.5596 - accuracy: 0.4587 - val_loss: 2.4243 - val_accuracy: 0.2843

Epoch 00063: val_loss did not improve from 2.09852
Epoch 64/100
11442/11442 - 19s - loss: 1.5610 - accuracy: 0.4595 - val_loss: 2.4223 - val_accuracy: 0.2820

Epoch 00064: val_loss did not improve from 2.09852
Epoch 65/100
11442/11442 - 19s - loss: 1.5593 - accuracy: 0.4612 - val_loss: 2.4509 - val_accuracy: 0.2783

Epoch 00065: val_loss did not improve from 2.09852
Epoch 66/100
11442/11442 - 19s - loss: 1.5536 - accuracy: 0.4605 - val_loss: 2.4588 - val_accuracy: 0.2865

Epoch 00066: val_loss did not improve from 2.09852
Epoch 67/100
11442/11442 - 19s - loss: 1.5554 - accuracy: 0.4619 - val_loss: 2.3950 - val_accuracy: 0.2870

Epoch 00067: val_loss did not improve from 2.09852
Epoch 68/100
11442/11442 - 19s - loss: 1.5540 - accuracy: 0.4627 - val_loss: 2.4406 - val_accuracy: 0.2846

Epoch 00068: val_loss did not improve from 2.09852
Epoch 69/100
11442/11442 - 18s - loss: 1.5562 - accuracy: 0.4625 - val_loss: 2.4170 - val_accuracy: 0.2890

Epoch 00069: val_loss did not improve from 2.09852
Epoch 70/100
11442/11442 - 19s - loss: 1.5535 - accuracy: 0.4628 - val_loss: 2.4521 - val_accuracy: 0.2721

Epoch 00070: val_loss did not improve from 2.09852
Epoch 71/100
11442/11442 - 18s - loss: 1.5523 - accuracy: 0.4617 - val_loss: 2.3645 - val_accuracy: 0.2831

Epoch 00071: val_loss did not improve from 2.09852
Epoch 72/100
11442/11442 - 18s - loss: 1.5524 - accuracy: 0.4617 - val_loss: 2.3974 - val_accuracy: 0.2823

Epoch 00072: val_loss did not improve from 2.09852
Epoch 73/100
11442/11442 - 19s - loss: 1.5500 - accuracy: 0.4635 - val_loss: 2.4677 - val_accuracy: 0.2852

Epoch 00073: val_loss did not improve from 2.09852
Epoch 74/100
11442/11442 - 18s - loss: 1.5479 - accuracy: 0.4641 - val_loss: 2.5214 - val_accuracy: 0.2619

Epoch 00074: val_loss did not improve from 2.09852
Epoch 75/100
11442/11442 - 19s - loss: 1.5488 - accuracy: 0.4639 - val_loss: 2.4647 - val_accuracy: 0.2636

Epoch 00075: val_loss did not improve from 2.09852
Epoch 76/100
11442/11442 - 19s - loss: 1.5476 - accuracy: 0.4653 - val_loss: 2.6607 - val_accuracy: 0.2775

Epoch 00076: val_loss did not improve from 2.09852
Epoch 77/100
11442/11442 - 18s - loss: 1.5473 - accuracy: 0.4646 - val_loss: 2.4907 - val_accuracy: 0.2739

Epoch 00077: val_loss did not improve from 2.09852
Epoch 78/100
11442/11442 - 18s - loss: 1.5472 - accuracy: 0.4645 - val_loss: 2.5138 - val_accuracy: 0.2842

Epoch 00078: val_loss did not improve from 2.09852
Epoch 79/100
11442/11442 - 18s - loss: 1.5469 - accuracy: 0.4639 - val_loss: 2.4334 - val_accuracy: 0.2859

Epoch 00079: val_loss did not improve from 2.09852
Epoch 80/100
11442/11442 - 19s - loss: 1.5489 - accuracy: 0.4642 - val_loss: 2.5325 - val_accuracy: 0.2772

Epoch 00080: val_loss did not improve from 2.09852
Epoch 81/100
11442/11442 - 19s - loss: 1.5453 - accuracy: 0.4660 - val_loss: 2.4601 - val_accuracy: 0.2858

Epoch 00081: val_loss did not improve from 2.09852
Epoch 82/100
11442/11442 - 19s - loss: 1.5460 - accuracy: 0.4633 - val_loss: 2.4649 - val_accuracy: 0.2794

Epoch 00082: val_loss did not improve from 2.09852
Epoch 83/100
11442/11442 - 19s - loss: 1.5429 - accuracy: 0.4650 - val_loss: 2.3944 - val_accuracy: 0.2747

Epoch 00083: val_loss did not improve from 2.09852
Epoch 84/100
11442/11442 - 19s - loss: 1.5438 - accuracy: 0.4641 - val_loss: 2.4387 - val_accuracy: 0.2834

Epoch 00084: val_loss did not improve from 2.09852
Epoch 85/100
11442/11442 - 19s - loss: 1.5423 - accuracy: 0.4668 - val_loss: 2.4166 - val_accuracy: 0.2839

Epoch 00085: val_loss did not improve from 2.09852
Epoch 86/100
11442/11442 - 19s - loss: 1.5435 - accuracy: 0.4643 - val_loss: 2.4154 - val_accuracy: 0.2751

Epoch 00086: val_loss did not improve from 2.09852
Epoch 87/100
11442/11442 - 19s - loss: 1.5428 - accuracy: 0.4653 - val_loss: 2.4048 - val_accuracy: 0.2755

Epoch 00087: val_loss did not improve from 2.09852
Epoch 88/100
11442/11442 - 19s - loss: 1.5423 - accuracy: 0.4670 - val_loss: 2.5464 - val_accuracy: 0.2796

Epoch 00088: val_loss did not improve from 2.09852
Epoch 89/100
11442/11442 - 18s - loss: 1.5424 - accuracy: 0.4678 - val_loss: 2.3745 - val_accuracy: 0.2874

Epoch 00089: val_loss did not improve from 2.09852
Epoch 90/100
11442/11442 - 19s - loss: 1.5399 - accuracy: 0.4674 - val_loss: 2.5097 - val_accuracy: 0.2782

Epoch 00090: val_loss did not improve from 2.09852
Epoch 91/100
11442/11442 - 18s - loss: 1.5392 - accuracy: 0.4680 - val_loss: 2.6067 - val_accuracy: 0.2785

Epoch 00091: val_loss did not improve from 2.09852
Epoch 92/100
11442/11442 - 19s - loss: 1.5416 - accuracy: 0.4660 - val_loss: 2.3968 - val_accuracy: 0.2877

Epoch 00092: val_loss did not improve from 2.09852
Epoch 93/100
11442/11442 - 19s - loss: 1.5373 - accuracy: 0.4676 - val_loss: 2.6864 - val_accuracy: 0.2802

Epoch 00093: val_loss did not improve from 2.09852
Epoch 94/100
11442/11442 - 19s - loss: 1.5367 - accuracy: 0.4682 - val_loss: 2.5102 - val_accuracy: 0.2756

Epoch 00094: val_loss did not improve from 2.09852
Epoch 95/100
11442/11442 - 19s - loss: 1.5396 - accuracy: 0.4659 - val_loss: 2.4774 - val_accuracy: 0.2789

Epoch 00095: val_loss did not improve from 2.09852
Epoch 96/100
11442/11442 - 18s - loss: 1.5392 - accuracy: 0.4678 - val_loss: 2.4790 - val_accuracy: 0.2733

Epoch 00096: val_loss did not improve from 2.09852
Epoch 97/100
11442/11442 - 18s - loss: 1.5351 - accuracy: 0.4677 - val_loss: 2.4662 - val_accuracy: 0.2787

Epoch 00097: val_loss did not improve from 2.09852
Epoch 98/100
11442/11442 - 18s - loss: 1.5372 - accuracy: 0.4675 - val_loss: 2.3663 - val_accuracy: 0.2901

Epoch 00098: val_loss did not improve from 2.09852
Epoch 99/100
11442/11442 - 18s - loss: 1.5354 - accuracy: 0.4680 - val_loss: 2.4332 - val_accuracy: 0.2807

Epoch 00099: val_loss did not improve from 2.09852
Epoch 100/100
11442/11442 - 18s - loss: 1.5368 - accuracy: 0.4673 - val_loss: 2.5407 - val_accuracy: 0.2791

Epoch 00100: val_loss did not improve from 2.09852
