Before oversampling: Counter({0.0: 22772, 10.0: 15114, 50.0: 15085, 90.0: 15054, 30.0: 14964, 70.0: 14771, 92.0: 7628, 100.0: 7624})
After oversampling: Counter({100.0: 22772, 92.0: 22772, 90.0: 22772, 10.0: 22772, 0.0: 22772, 70.0: 22772, 50.0: 22772, 30.0: 22772})
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
conv (InputLayer)               [(None, 23, 1)]      0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 23, 64)       384         conv[0][0]                       
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 23, 64)       20544       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 23, 64)       20544       conv1d_1[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1472)         0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 17)           25041       flatten[0][0]                    
__________________________________________________________________________________________________
cat (InputLayer)                [(None, 0)]          0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 8)            144         dense[0][0]                      
==================================================================================================
Total params: 66,657
Trainable params: 66,657
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
18218/18218 - 18s - loss: 1.3720 - accuracy: 0.4584 - val_loss: 1.3185 - val_accuracy: 0.4789

Epoch 00001: val_loss improved from inf to 1.31848, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 2/100
18218/18218 - 17s - loss: 1.2702 - accuracy: 0.5035 - val_loss: 1.2990 - val_accuracy: 0.4834

Epoch 00002: val_loss improved from 1.31848 to 1.29901, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 3/100
18218/18218 - 17s - loss: 1.2444 - accuracy: 0.5146 - val_loss: 1.2729 - val_accuracy: 0.5046

Epoch 00003: val_loss improved from 1.29901 to 1.27293, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 4/100
18218/18218 - 17s - loss: 1.2270 - accuracy: 0.5243 - val_loss: 1.2553 - val_accuracy: 0.5058

Epoch 00004: val_loss improved from 1.27293 to 1.25533, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 5/100
18218/18218 - 17s - loss: 1.2132 - accuracy: 0.5296 - val_loss: 1.2444 - val_accuracy: 0.5162

Epoch 00005: val_loss improved from 1.25533 to 1.24439, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 6/100
18218/18218 - 17s - loss: 1.2045 - accuracy: 0.5348 - val_loss: 1.2527 - val_accuracy: 0.5121

Epoch 00006: val_loss did not improve from 1.24439
Epoch 7/100
18218/18218 - 17s - loss: 1.1971 - accuracy: 0.5385 - val_loss: 1.2527 - val_accuracy: 0.5150

Epoch 00007: val_loss did not improve from 1.24439
Epoch 8/100
18218/18218 - 19s - loss: 1.1897 - accuracy: 0.5411 - val_loss: 1.2411 - val_accuracy: 0.5159

Epoch 00008: val_loss improved from 1.24439 to 1.24108, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 9/100
18218/18218 - 19s - loss: 1.1825 - accuracy: 0.5434 - val_loss: 1.2290 - val_accuracy: 0.5257

Epoch 00009: val_loss improved from 1.24108 to 1.22905, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 10/100
18218/18218 - 20s - loss: 1.1764 - accuracy: 0.5477 - val_loss: 1.2250 - val_accuracy: 0.5294

Epoch 00010: val_loss improved from 1.22905 to 1.22496, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 11/100
18218/18218 - 19s - loss: 1.1715 - accuracy: 0.5497 - val_loss: 1.2551 - val_accuracy: 0.5153

Epoch 00011: val_loss did not improve from 1.22496
Epoch 12/100
18218/18218 - 19s - loss: 1.1673 - accuracy: 0.5507 - val_loss: 1.2176 - val_accuracy: 0.5296

Epoch 00012: val_loss improved from 1.22496 to 1.21759, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 13/100
18218/18218 - 19s - loss: 1.1636 - accuracy: 0.5533 - val_loss: 1.2243 - val_accuracy: 0.5297

Epoch 00013: val_loss did not improve from 1.21759
Epoch 14/100
18218/18218 - 19s - loss: 1.1595 - accuracy: 0.5555 - val_loss: 1.2297 - val_accuracy: 0.5221

Epoch 00014: val_loss did not improve from 1.21759
Epoch 15/100
18218/18218 - 17s - loss: 1.1550 - accuracy: 0.5574 - val_loss: 1.2168 - val_accuracy: 0.5339

Epoch 00015: val_loss improved from 1.21759 to 1.21682, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 16/100
18218/18218 - 17s - loss: 1.1512 - accuracy: 0.5592 - val_loss: 1.2288 - val_accuracy: 0.5298

Epoch 00016: val_loss did not improve from 1.21682
Epoch 17/100
18218/18218 - 19s - loss: 1.1481 - accuracy: 0.5602 - val_loss: 1.2255 - val_accuracy: 0.5300

Epoch 00017: val_loss did not improve from 1.21682
Epoch 18/100
18218/18218 - 19s - loss: 1.1442 - accuracy: 0.5619 - val_loss: 1.2108 - val_accuracy: 0.5366

Epoch 00018: val_loss improved from 1.21682 to 1.21079, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 19/100
18218/18218 - 19s - loss: 1.1410 - accuracy: 0.5641 - val_loss: 1.2187 - val_accuracy: 0.5274

Epoch 00019: val_loss did not improve from 1.21079
Epoch 20/100
18218/18218 - 19s - loss: 1.1386 - accuracy: 0.5639 - val_loss: 1.2127 - val_accuracy: 0.5310

Epoch 00020: val_loss did not improve from 1.21079
Epoch 21/100
18218/18218 - 19s - loss: 1.1360 - accuracy: 0.5650 - val_loss: 1.2321 - val_accuracy: 0.5265

Epoch 00021: val_loss did not improve from 1.21079
Epoch 22/100
18218/18218 - 19s - loss: 1.1327 - accuracy: 0.5656 - val_loss: 1.2218 - val_accuracy: 0.5322

Epoch 00022: val_loss did not improve from 1.21079
Epoch 23/100
18218/18218 - 19s - loss: 1.1301 - accuracy: 0.5672 - val_loss: 1.2311 - val_accuracy: 0.5246

Epoch 00023: val_loss did not improve from 1.21079
Epoch 24/100
18218/18218 - 17s - loss: 1.1277 - accuracy: 0.5675 - val_loss: 1.2261 - val_accuracy: 0.5262

Epoch 00024: val_loss did not improve from 1.21079
Epoch 25/100
18218/18218 - 17s - loss: 1.1245 - accuracy: 0.5696 - val_loss: 1.2183 - val_accuracy: 0.5359

Epoch 00025: val_loss did not improve from 1.21079
Epoch 26/100
18218/18218 - 17s - loss: 1.1204 - accuracy: 0.5706 - val_loss: 1.2167 - val_accuracy: 0.5391

Epoch 00026: val_loss did not improve from 1.21079
Epoch 27/100
18218/18218 - 17s - loss: 1.1191 - accuracy: 0.5721 - val_loss: 1.2433 - val_accuracy: 0.5225

Epoch 00027: val_loss did not improve from 1.21079
Epoch 28/100
18218/18218 - 17s - loss: 1.1170 - accuracy: 0.5728 - val_loss: 1.2376 - val_accuracy: 0.5289

Epoch 00028: val_loss did not improve from 1.21079
Epoch 29/100
18218/18218 - 17s - loss: 1.1139 - accuracy: 0.5745 - val_loss: 1.2324 - val_accuracy: 0.5280

Epoch 00029: val_loss did not improve from 1.21079
Epoch 30/100
18218/18218 - 17s - loss: 1.1119 - accuracy: 0.5743 - val_loss: 1.2211 - val_accuracy: 0.5339

Epoch 00030: val_loss did not improve from 1.21079
Epoch 31/100
18218/18218 - 17s - loss: 1.1099 - accuracy: 0.5756 - val_loss: 1.2140 - val_accuracy: 0.5299

Epoch 00031: val_loss did not improve from 1.21079
Epoch 32/100
18218/18218 - 17s - loss: 1.1065 - accuracy: 0.5773 - val_loss: 1.2168 - val_accuracy: 0.5312

Epoch 00032: val_loss did not improve from 1.21079
Epoch 33/100
18218/18218 - 17s - loss: 1.1059 - accuracy: 0.5769 - val_loss: 1.2110 - val_accuracy: 0.5387

Epoch 00033: val_loss did not improve from 1.21079
Epoch 34/100
18218/18218 - 17s - loss: 1.1040 - accuracy: 0.5784 - val_loss: 1.2145 - val_accuracy: 0.5363

Epoch 00034: val_loss did not improve from 1.21079
Epoch 35/100
18218/18218 - 20s - loss: 1.1013 - accuracy: 0.5795 - val_loss: 1.2016 - val_accuracy: 0.5341

Epoch 00035: val_loss improved from 1.21079 to 1.20164, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 36/100
18218/18218 - 18s - loss: 1.0992 - accuracy: 0.5808 - val_loss: 1.2077 - val_accuracy: 0.5363

Epoch 00036: val_loss did not improve from 1.20164
Epoch 37/100
18218/18218 - 17s - loss: 1.0954 - accuracy: 0.5811 - val_loss: 1.2191 - val_accuracy: 0.5379

Epoch 00037: val_loss did not improve from 1.20164
Epoch 38/100
18218/18218 - 18s - loss: 1.0948 - accuracy: 0.5818 - val_loss: 1.2215 - val_accuracy: 0.5335

Epoch 00038: val_loss did not improve from 1.20164
Epoch 39/100
18218/18218 - 17s - loss: 1.0940 - accuracy: 0.5839 - val_loss: 1.2341 - val_accuracy: 0.5283

Epoch 00039: val_loss did not improve from 1.20164
Epoch 40/100
18218/18218 - 17s - loss: 1.0919 - accuracy: 0.5828 - val_loss: 1.1992 - val_accuracy: 0.5457

Epoch 00040: val_loss improved from 1.20164 to 1.19920, saving model to ./results/CNN_GLCM_C8/cp.ckpt
Epoch 41/100
18218/18218 - 17s - loss: 1.0903 - accuracy: 0.5841 - val_loss: 1.2272 - val_accuracy: 0.5327

Epoch 00041: val_loss did not improve from 1.19920
Epoch 42/100
18218/18218 - 17s - loss: 1.0893 - accuracy: 0.5834 - val_loss: 1.2008 - val_accuracy: 0.5512

Epoch 00042: val_loss did not improve from 1.19920
Epoch 43/100
18218/18218 - 17s - loss: 1.0881 - accuracy: 0.5853 - val_loss: 1.2239 - val_accuracy: 0.5349

Epoch 00043: val_loss did not improve from 1.19920
Epoch 44/100
18218/18218 - 17s - loss: 1.0865 - accuracy: 0.5856 - val_loss: 1.2026 - val_accuracy: 0.5431

Epoch 00044: val_loss did not improve from 1.19920
Epoch 45/100
18218/18218 - 17s - loss: 1.0847 - accuracy: 0.5869 - val_loss: 1.2068 - val_accuracy: 0.5388

Epoch 00045: val_loss did not improve from 1.19920
Epoch 46/100
18218/18218 - 17s - loss: 1.0830 - accuracy: 0.5865 - val_loss: 1.2317 - val_accuracy: 0.5385

Epoch 00046: val_loss did not improve from 1.19920
Epoch 47/100
18218/18218 - 17s - loss: 1.0828 - accuracy: 0.5874 - val_loss: 1.2097 - val_accuracy: 0.5389

Epoch 00047: val_loss did not improve from 1.19920
Epoch 48/100
18218/18218 - 17s - loss: 1.0808 - accuracy: 0.5888 - val_loss: 1.2312 - val_accuracy: 0.5343

Epoch 00048: val_loss did not improve from 1.19920
Epoch 49/100
18218/18218 - 17s - loss: 1.0800 - accuracy: 0.5871 - val_loss: 1.2006 - val_accuracy: 0.5443

Epoch 00049: val_loss did not improve from 1.19920
Epoch 50/100
18218/18218 - 17s - loss: 1.0779 - accuracy: 0.5904 - val_loss: 1.2050 - val_accuracy: 0.5476

Epoch 00050: val_loss did not improve from 1.19920
Epoch 51/100
18218/18218 - 17s - loss: 1.0792 - accuracy: 0.5899 - val_loss: 1.2072 - val_accuracy: 0.5377

Epoch 00051: val_loss did not improve from 1.19920
Epoch 52/100
18218/18218 - 17s - loss: 1.0760 - accuracy: 0.5902 - val_loss: 1.2264 - val_accuracy: 0.5295

Epoch 00052: val_loss did not improve from 1.19920
Epoch 53/100
18218/18218 - 17s - loss: 1.0750 - accuracy: 0.5900 - val_loss: 1.2127 - val_accuracy: 0.5411

Epoch 00053: val_loss did not improve from 1.19920
Epoch 54/100
18218/18218 - 18s - loss: 1.0742 - accuracy: 0.5911 - val_loss: 1.2290 - val_accuracy: 0.5328

Epoch 00054: val_loss did not improve from 1.19920
Epoch 55/100
18218/18218 - 18s - loss: 1.0726 - accuracy: 0.5924 - val_loss: 1.2255 - val_accuracy: 0.5377

Epoch 00055: val_loss did not improve from 1.19920
Epoch 56/100
18218/18218 - 18s - loss: 1.0730 - accuracy: 0.5905 - val_loss: 1.2156 - val_accuracy: 0.5458

Epoch 00056: val_loss did not improve from 1.19920
Epoch 57/100
18218/18218 - 17s - loss: 1.0718 - accuracy: 0.5921 - val_loss: 1.2354 - val_accuracy: 0.5364

Epoch 00057: val_loss did not improve from 1.19920
Epoch 58/100
18218/18218 - 17s - loss: 1.0704 - accuracy: 0.5939 - val_loss: 1.2290 - val_accuracy: 0.5342

Epoch 00058: val_loss did not improve from 1.19920
Epoch 59/100
18218/18218 - 17s - loss: 1.0706 - accuracy: 0.5916 - val_loss: 1.2116 - val_accuracy: 0.5409

Epoch 00059: val_loss did not improve from 1.19920
Epoch 60/100
18218/18218 - 17s - loss: 1.0684 - accuracy: 0.5941 - val_loss: 1.2110 - val_accuracy: 0.5387

Epoch 00060: val_loss did not improve from 1.19920
Epoch 61/100
18218/18218 - 17s - loss: 1.0670 - accuracy: 0.5939 - val_loss: 1.2361 - val_accuracy: 0.5330

Epoch 00061: val_loss did not improve from 1.19920
Epoch 62/100
18218/18218 - 17s - loss: 1.0665 - accuracy: 0.5931 - val_loss: 1.2221 - val_accuracy: 0.5449

Epoch 00062: val_loss did not improve from 1.19920
Epoch 63/100
18218/18218 - 17s - loss: 1.0673 - accuracy: 0.5939 - val_loss: 1.2356 - val_accuracy: 0.5367

Epoch 00063: val_loss did not improve from 1.19920
Epoch 64/100
18218/18218 - 17s - loss: 1.0672 - accuracy: 0.5934 - val_loss: 1.2324 - val_accuracy: 0.5346

Epoch 00064: val_loss did not improve from 1.19920
Epoch 65/100
18218/18218 - 17s - loss: 1.0637 - accuracy: 0.5942 - val_loss: 1.2182 - val_accuracy: 0.5471

Epoch 00065: val_loss did not improve from 1.19920
Epoch 66/100
18218/18218 - 17s - loss: 1.0631 - accuracy: 0.5945 - val_loss: 1.2283 - val_accuracy: 0.5419

Epoch 00066: val_loss did not improve from 1.19920
Epoch 67/100
18218/18218 - 17s - loss: 1.0639 - accuracy: 0.5949 - val_loss: 1.2214 - val_accuracy: 0.5377

Epoch 00067: val_loss did not improve from 1.19920
Epoch 68/100
18218/18218 - 17s - loss: 1.0621 - accuracy: 0.5953 - val_loss: 1.2141 - val_accuracy: 0.5506

Epoch 00068: val_loss did not improve from 1.19920
Epoch 69/100
18218/18218 - 17s - loss: 1.0629 - accuracy: 0.5951 - val_loss: 1.2441 - val_accuracy: 0.5287

Epoch 00069: val_loss did not improve from 1.19920
Epoch 70/100
18218/18218 - 17s - loss: 1.0614 - accuracy: 0.5968 - val_loss: 1.2308 - val_accuracy: 0.5373

Epoch 00070: val_loss did not improve from 1.19920
Epoch 71/100
18218/18218 - 17s - loss: 1.0591 - accuracy: 0.5973 - val_loss: 1.2215 - val_accuracy: 0.5411

Epoch 00071: val_loss did not improve from 1.19920
Epoch 72/100
18218/18218 - 17s - loss: 1.0595 - accuracy: 0.5971 - val_loss: 1.2258 - val_accuracy: 0.5379

Epoch 00072: val_loss did not improve from 1.19920
Epoch 73/100
18218/18218 - 17s - loss: 1.0596 - accuracy: 0.5971 - val_loss: 1.2519 - val_accuracy: 0.5329

Epoch 00073: val_loss did not improve from 1.19920
Epoch 74/100
18218/18218 - 18s - loss: 1.0591 - accuracy: 0.5953 - val_loss: 1.2242 - val_accuracy: 0.5499

Epoch 00074: val_loss did not improve from 1.19920
Epoch 75/100
18218/18218 - 17s - loss: 1.0586 - accuracy: 0.5981 - val_loss: 1.2416 - val_accuracy: 0.5340

Epoch 00075: val_loss did not improve from 1.19920
Epoch 76/100
18218/18218 - 17s - loss: 1.0567 - accuracy: 0.5974 - val_loss: 1.2377 - val_accuracy: 0.5278

Epoch 00076: val_loss did not improve from 1.19920
Epoch 77/100
18218/18218 - 17s - loss: 1.0580 - accuracy: 0.5978 - val_loss: 1.2289 - val_accuracy: 0.5449

Epoch 00077: val_loss did not improve from 1.19920
Epoch 78/100
18218/18218 - 17s - loss: 1.0561 - accuracy: 0.5970 - val_loss: 1.2090 - val_accuracy: 0.5485

Epoch 00078: val_loss did not improve from 1.19920
Epoch 79/100
18218/18218 - 17s - loss: 1.0545 - accuracy: 0.5998 - val_loss: 1.2154 - val_accuracy: 0.5442

Epoch 00079: val_loss did not improve from 1.19920
Epoch 80/100
18218/18218 - 17s - loss: 1.0556 - accuracy: 0.5986 - val_loss: 1.2397 - val_accuracy: 0.5382

Epoch 00080: val_loss did not improve from 1.19920
Epoch 81/100
18218/18218 - 17s - loss: 1.0536 - accuracy: 0.6006 - val_loss: 1.2379 - val_accuracy: 0.5406

Epoch 00081: val_loss did not improve from 1.19920
Epoch 82/100
18218/18218 - 17s - loss: 1.0518 - accuracy: 0.5997 - val_loss: 1.2339 - val_accuracy: 0.5444

Epoch 00082: val_loss did not improve from 1.19920
Epoch 83/100
18218/18218 - 17s - loss: 1.0546 - accuracy: 0.5994 - val_loss: 1.2242 - val_accuracy: 0.5445

Epoch 00083: val_loss did not improve from 1.19920
Epoch 84/100
18218/18218 - 17s - loss: 1.0541 - accuracy: 0.6002 - val_loss: 1.2275 - val_accuracy: 0.5374

Epoch 00084: val_loss did not improve from 1.19920
Epoch 85/100
18218/18218 - 17s - loss: 1.0522 - accuracy: 0.6011 - val_loss: 1.2474 - val_accuracy: 0.5351

Epoch 00085: val_loss did not improve from 1.19920
Epoch 86/100
18218/18218 - 17s - loss: 1.0517 - accuracy: 0.5985 - val_loss: 1.2401 - val_accuracy: 0.5369

Epoch 00086: val_loss did not improve from 1.19920
Epoch 87/100
18218/18218 - 17s - loss: 1.0491 - accuracy: 0.6017 - val_loss: 1.2420 - val_accuracy: 0.5432

Epoch 00087: val_loss did not improve from 1.19920
Epoch 88/100
18218/18218 - 17s - loss: 1.0505 - accuracy: 0.6012 - val_loss: 1.2372 - val_accuracy: 0.5408

Epoch 00088: val_loss did not improve from 1.19920
Epoch 89/100
18218/18218 - 17s - loss: 1.0502 - accuracy: 0.6005 - val_loss: 1.2332 - val_accuracy: 0.5395

Epoch 00089: val_loss did not improve from 1.19920
Epoch 90/100
18218/18218 - 17s - loss: 1.0500 - accuracy: 0.6011 - val_loss: 1.2338 - val_accuracy: 0.5474

Epoch 00090: val_loss did not improve from 1.19920
Epoch 91/100
18218/18218 - 17s - loss: 1.0508 - accuracy: 0.6014 - val_loss: 1.2502 - val_accuracy: 0.5371

Epoch 00091: val_loss did not improve from 1.19920
Epoch 92/100
18218/18218 - 17s - loss: 1.0506 - accuracy: 0.6011 - val_loss: 1.2610 - val_accuracy: 0.5413

Epoch 00092: val_loss did not improve from 1.19920
Epoch 93/100
18218/18218 - 17s - loss: 1.0479 - accuracy: 0.6029 - val_loss: 1.2351 - val_accuracy: 0.5415

Epoch 00093: val_loss did not improve from 1.19920
Epoch 94/100
18218/18218 - 17s - loss: 1.0461 - accuracy: 0.6019 - val_loss: 1.2829 - val_accuracy: 0.5327

Epoch 00094: val_loss did not improve from 1.19920
Epoch 95/100
18218/18218 - 17s - loss: 1.0479 - accuracy: 0.6023 - val_loss: 1.2765 - val_accuracy: 0.5405

Epoch 00095: val_loss did not improve from 1.19920
Epoch 96/100
18218/18218 - 17s - loss: 1.0447 - accuracy: 0.6029 - val_loss: 1.2524 - val_accuracy: 0.5367

Epoch 00096: val_loss did not improve from 1.19920
Epoch 97/100
18218/18218 - 17s - loss: 1.0461 - accuracy: 0.6025 - val_loss: 1.2548 - val_accuracy: 0.5376

Epoch 00097: val_loss did not improve from 1.19920
Epoch 98/100
18218/18218 - 17s - loss: 1.0486 - accuracy: 0.6012 - val_loss: 1.2528 - val_accuracy: 0.5402

Epoch 00098: val_loss did not improve from 1.19920
Epoch 99/100
18218/18218 - 17s - loss: 1.0473 - accuracy: 0.6022 - val_loss: 1.2593 - val_accuracy: 0.5343

Epoch 00099: val_loss did not improve from 1.19920
Epoch 100/100
18218/18218 - 17s - loss: 1.0445 - accuracy: 0.6042 - val_loss: 1.2364 - val_accuracy: 0.5476

Epoch 00100: val_loss did not improve from 1.19920
