Before oversampling: Counter({50.0: 38006, 0.0: 37856, 1.0: 37836, 70.0: 37779, 20.0: 37752, 80.0: 37699, 10.0: 37678, 60.0: 37677, 92.0: 37673, 2.0: 37641, 91.0: 37630, 30.0: 37505, 90.0: 37480, 100.0: 37475, 40.0: 37235})
After oversampling: Counter({50.0: 38006, 40.0: 38006, 0.0: 37856, 1.0: 37836, 70.0: 37779, 20.0: 37752, 80.0: 37699, 10.0: 37678, 60.0: 37677, 92.0: 37673, 2.0: 37641, 91.0: 37630, 30.0: 37505, 90.0: 37480, 100.0: 37475})
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 14, 64)            384       
_________________________________________________________________
dense (Dense)                (None, 14, 128)           8320      
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 7, 128)            0         
_________________________________________________________________
flatten (Flatten)            (None, 896)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                13455     
=================================================================
Total params: 22,159
Trainable params: 22,159
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
56570/56570 - 43s - loss: 1.9138 - accuracy: 0.3347 - val_loss: 2.1982 - val_accuracy: 0.2671

Epoch 00001: val_loss improved from inf to 2.19824, saving model to ./results/CNN_trial_6/cp.ckpt
Epoch 2/100
56570/56570 - 43s - loss: 1.7916 - accuracy: 0.3778 - val_loss: 2.2621 - val_accuracy: 0.2726

Epoch 00002: val_loss did not improve from 2.19824
Epoch 3/100
56570/56570 - 43s - loss: 1.7533 - accuracy: 0.3932 - val_loss: 2.2150 - val_accuracy: 0.2790

Epoch 00003: val_loss did not improve from 2.19824
Epoch 4/100
56570/56570 - 43s - loss: 1.7315 - accuracy: 0.4011 - val_loss: 2.3015 - val_accuracy: 0.2623

Epoch 00004: val_loss did not improve from 2.19824
Epoch 5/100
56570/56570 - 43s - loss: 1.7174 - accuracy: 0.4061 - val_loss: 2.2953 - val_accuracy: 0.2675

Epoch 00005: val_loss did not improve from 2.19824
Epoch 6/100
56570/56570 - 43s - loss: 1.7068 - accuracy: 0.4107 - val_loss: 2.2732 - val_accuracy: 0.2794

Epoch 00006: val_loss did not improve from 2.19824
Epoch 7/100
56570/56570 - 43s - loss: 1.6987 - accuracy: 0.4139 - val_loss: 2.2448 - val_accuracy: 0.2831

Epoch 00007: val_loss did not improve from 2.19824
Epoch 8/100
56570/56570 - 44s - loss: 1.6931 - accuracy: 0.4142 - val_loss: 2.3023 - val_accuracy: 0.2719

Epoch 00008: val_loss did not improve from 2.19824
Epoch 9/100
56570/56570 - 42s - loss: 1.6888 - accuracy: 0.4170 - val_loss: 2.4017 - val_accuracy: 0.2551

Epoch 00009: val_loss did not improve from 2.19824
Epoch 10/100
56570/56570 - 44s - loss: 1.6854 - accuracy: 0.4179 - val_loss: 2.3321 - val_accuracy: 0.2689

Epoch 00010: val_loss did not improve from 2.19824
Epoch 11/100
56570/56570 - 43s - loss: 1.6833 - accuracy: 0.4191 - val_loss: 2.3163 - val_accuracy: 0.2680

Epoch 00011: val_loss did not improve from 2.19824
Epoch 12/100
56570/56570 - 43s - loss: 1.6807 - accuracy: 0.4192 - val_loss: 2.3640 - val_accuracy: 0.2775

Epoch 00012: val_loss did not improve from 2.19824
Epoch 13/100
56570/56570 - 43s - loss: 1.6780 - accuracy: 0.4208 - val_loss: 2.3513 - val_accuracy: 0.2698

Epoch 00013: val_loss did not improve from 2.19824
Epoch 14/100
56570/56570 - 43s - loss: 1.6772 - accuracy: 0.4214 - val_loss: 2.3247 - val_accuracy: 0.2809

Epoch 00014: val_loss did not improve from 2.19824
Epoch 15/100
56570/56570 - 43s - loss: 1.6758 - accuracy: 0.4216 - val_loss: 2.3442 - val_accuracy: 0.2769

Epoch 00015: val_loss did not improve from 2.19824
Epoch 16/100
56570/56570 - 43s - loss: 1.6749 - accuracy: 0.4227 - val_loss: 2.3258 - val_accuracy: 0.2773

Epoch 00016: val_loss did not improve from 2.19824
Epoch 17/100
56570/56570 - 44s - loss: 1.6733 - accuracy: 0.4229 - val_loss: 2.3618 - val_accuracy: 0.2858

Epoch 00017: val_loss did not improve from 2.19824
Epoch 18/100
56570/56570 - 43s - loss: 1.6736 - accuracy: 0.4230 - val_loss: 2.3414 - val_accuracy: 0.2766

Epoch 00018: val_loss did not improve from 2.19824
Epoch 19/100
56570/56570 - 43s - loss: 1.6723 - accuracy: 0.4233 - val_loss: 2.3045 - val_accuracy: 0.2814

Epoch 00019: val_loss did not improve from 2.19824
Epoch 20/100
56570/56570 - 43s - loss: 1.6719 - accuracy: 0.4241 - val_loss: 2.3542 - val_accuracy: 0.2839

Epoch 00020: val_loss did not improve from 2.19824
Epoch 21/100
56570/56570 - 43s - loss: 1.6722 - accuracy: 0.4227 - val_loss: 2.3441 - val_accuracy: 0.2609

Epoch 00021: val_loss did not improve from 2.19824
Epoch 22/100
56570/56570 - 43s - loss: 1.6701 - accuracy: 0.4249 - val_loss: 2.3971 - val_accuracy: 0.2740

Epoch 00022: val_loss did not improve from 2.19824
Epoch 23/100
56570/56570 - 43s - loss: 1.6705 - accuracy: 0.4249 - val_loss: 2.3893 - val_accuracy: 0.2749

Epoch 00023: val_loss did not improve from 2.19824
Epoch 24/100
56570/56570 - 43s - loss: 1.6710 - accuracy: 0.4244 - val_loss: 2.3287 - val_accuracy: 0.2818

Epoch 00024: val_loss did not improve from 2.19824
Epoch 25/100
56570/56570 - 43s - loss: 1.6717 - accuracy: 0.4249 - val_loss: 2.3611 - val_accuracy: 0.2541

Epoch 00025: val_loss did not improve from 2.19824
Epoch 26/100
56570/56570 - 44s - loss: 1.6708 - accuracy: 0.4239 - val_loss: 2.4390 - val_accuracy: 0.2622

Epoch 00026: val_loss did not improve from 2.19824
Epoch 27/100
56570/56570 - 43s - loss: 1.6712 - accuracy: 0.4242 - val_loss: 2.3702 - val_accuracy: 0.2741

Epoch 00027: val_loss did not improve from 2.19824
Epoch 28/100
56570/56570 - 43s - loss: 1.6721 - accuracy: 0.4253 - val_loss: 2.3355 - val_accuracy: 0.2774

Epoch 00028: val_loss did not improve from 2.19824
Epoch 29/100
56570/56570 - 43s - loss: 1.6703 - accuracy: 0.4251 - val_loss: 2.3273 - val_accuracy: 0.2662

Epoch 00029: val_loss did not improve from 2.19824
Epoch 30/100
56570/56570 - 43s - loss: 1.6707 - accuracy: 0.4252 - val_loss: 2.3561 - val_accuracy: 0.2813

Epoch 00030: val_loss did not improve from 2.19824
Epoch 31/100
56570/56570 - 43s - loss: 1.6705 - accuracy: 0.4249 - val_loss: 2.3309 - val_accuracy: 0.2739

Epoch 00031: val_loss did not improve from 2.19824
Epoch 32/100
56570/56570 - 43s - loss: 1.6705 - accuracy: 0.4252 - val_loss: 2.3463 - val_accuracy: 0.2696

Epoch 00032: val_loss did not improve from 2.19824
Epoch 33/100
56570/56570 - 43s - loss: 1.6711 - accuracy: 0.4238 - val_loss: 2.3402 - val_accuracy: 0.2751

Epoch 00033: val_loss did not improve from 2.19824
Epoch 34/100
56570/56570 - 43s - loss: 1.6703 - accuracy: 0.4246 - val_loss: 2.3647 - val_accuracy: 0.2797

Epoch 00034: val_loss did not improve from 2.19824
Epoch 35/100
56570/56570 - 43s - loss: 1.6709 - accuracy: 0.4249 - val_loss: 2.3990 - val_accuracy: 0.2738

Epoch 00035: val_loss did not improve from 2.19824
Epoch 36/100
56570/56570 - 43s - loss: 1.6706 - accuracy: 0.4239 - val_loss: 2.4055 - val_accuracy: 0.2638

Epoch 00036: val_loss did not improve from 2.19824
Epoch 37/100
56570/56570 - 42s - loss: 1.6706 - accuracy: 0.4248 - val_loss: 2.3302 - val_accuracy: 0.2730

Epoch 00037: val_loss did not improve from 2.19824
Epoch 38/100
56570/56570 - 42s - loss: 1.6706 - accuracy: 0.4249 - val_loss: 2.3214 - val_accuracy: 0.2753

Epoch 00038: val_loss did not improve from 2.19824
Epoch 39/100
56570/56570 - 43s - loss: 1.6707 - accuracy: 0.4248 - val_loss: 2.3669 - val_accuracy: 0.2709

Epoch 00039: val_loss did not improve from 2.19824
Epoch 40/100
56570/56570 - 42s - loss: 1.6711 - accuracy: 0.4247 - val_loss: 2.4070 - val_accuracy: 0.2679

Epoch 00040: val_loss did not improve from 2.19824
Epoch 41/100
56570/56570 - 42s - loss: 1.6707 - accuracy: 0.4255 - val_loss: 2.3276 - val_accuracy: 0.2795

Epoch 00041: val_loss did not improve from 2.19824
Epoch 42/100
56570/56570 - 43s - loss: 1.6709 - accuracy: 0.4246 - val_loss: 2.2944 - val_accuracy: 0.2840

Epoch 00042: val_loss did not improve from 2.19824
Epoch 43/100
56570/56570 - 43s - loss: 1.6707 - accuracy: 0.4257 - val_loss: 2.4255 - val_accuracy: 0.2699

Epoch 00043: val_loss did not improve from 2.19824
Epoch 44/100
56570/56570 - 43s - loss: 1.6699 - accuracy: 0.4247 - val_loss: 2.3367 - val_accuracy: 0.2748

Epoch 00044: val_loss did not improve from 2.19824
Epoch 45/100
56570/56570 - 42s - loss: 1.6702 - accuracy: 0.4254 - val_loss: 2.4097 - val_accuracy: 0.2772

Epoch 00045: val_loss did not improve from 2.19824
Epoch 46/100
56570/56570 - 43s - loss: 1.6702 - accuracy: 0.4247 - val_loss: 2.4177 - val_accuracy: 0.2616

Epoch 00046: val_loss did not improve from 2.19824
Epoch 47/100
56570/56570 - 42s - loss: 1.6698 - accuracy: 0.4245 - val_loss: 2.3245 - val_accuracy: 0.2822

Epoch 00047: val_loss did not improve from 2.19824
Epoch 48/100
56570/56570 - 42s - loss: 1.6702 - accuracy: 0.4255 - val_loss: 2.3962 - val_accuracy: 0.2722

Epoch 00048: val_loss did not improve from 2.19824
Epoch 49/100
56570/56570 - 42s - loss: 1.6697 - accuracy: 0.4255 - val_loss: 2.4164 - val_accuracy: 0.2711

Epoch 00049: val_loss did not improve from 2.19824
Epoch 50/100
56570/56570 - 43s - loss: 1.6704 - accuracy: 0.4245 - val_loss: 2.3820 - val_accuracy: 0.2773

Epoch 00050: val_loss did not improve from 2.19824
Epoch 51/100
56570/56570 - 43s - loss: 1.6703 - accuracy: 0.4240 - val_loss: 2.3228 - val_accuracy: 0.2812

Epoch 00051: val_loss did not improve from 2.19824
Epoch 52/100
56570/56570 - 43s - loss: 1.6706 - accuracy: 0.4244 - val_loss: 2.3995 - val_accuracy: 0.2614

Epoch 00052: val_loss did not improve from 2.19824
Epoch 53/100
56570/56570 - 43s - loss: 1.6713 - accuracy: 0.4247 - val_loss: 2.4022 - val_accuracy: 0.2800

Epoch 00053: val_loss did not improve from 2.19824
Epoch 54/100
56570/56570 - 42s - loss: 1.6719 - accuracy: 0.4240 - val_loss: 2.3930 - val_accuracy: 0.2804

Epoch 00054: val_loss did not improve from 2.19824
Epoch 55/100
56570/56570 - 43s - loss: 1.6718 - accuracy: 0.4240 - val_loss: 2.4040 - val_accuracy: 0.2769

Epoch 00055: val_loss did not improve from 2.19824
Epoch 56/100
56570/56570 - 42s - loss: 1.6720 - accuracy: 0.4242 - val_loss: 2.3675 - val_accuracy: 0.2779

Epoch 00056: val_loss did not improve from 2.19824
Epoch 57/100
56570/56570 - 43s - loss: 1.6728 - accuracy: 0.4239 - val_loss: 2.3684 - val_accuracy: 0.2763

Epoch 00057: val_loss did not improve from 2.19824
Epoch 58/100
56570/56570 - 42s - loss: 1.6728 - accuracy: 0.4233 - val_loss: 2.4180 - val_accuracy: 0.2714

Epoch 00058: val_loss did not improve from 2.19824
Epoch 59/100
56570/56570 - 43s - loss: 1.6730 - accuracy: 0.4235 - val_loss: 2.4027 - val_accuracy: 0.2753

Epoch 00059: val_loss did not improve from 2.19824
Epoch 60/100
56570/56570 - 43s - loss: 1.6740 - accuracy: 0.4241 - val_loss: 2.4112 - val_accuracy: 0.2765

Epoch 00060: val_loss did not improve from 2.19824
Epoch 61/100
56570/56570 - 42s - loss: 1.6736 - accuracy: 0.4244 - val_loss: 2.4884 - val_accuracy: 0.2681

Epoch 00061: val_loss did not improve from 2.19824
Epoch 62/100
56570/56570 - 43s - loss: 1.6743 - accuracy: 0.4236 - val_loss: 2.3353 - val_accuracy: 0.2833

Epoch 00062: val_loss did not improve from 2.19824
Epoch 63/100
56570/56570 - 43s - loss: 1.6747 - accuracy: 0.4234 - val_loss: 2.3950 - val_accuracy: 0.2762

Epoch 00063: val_loss did not improve from 2.19824
Epoch 64/100
56570/56570 - 43s - loss: 1.6746 - accuracy: 0.4232 - val_loss: 2.3627 - val_accuracy: 0.2867

Epoch 00064: val_loss did not improve from 2.19824
Epoch 65/100
56570/56570 - 43s - loss: 1.6760 - accuracy: 0.4233 - val_loss: 2.2942 - val_accuracy: 0.2831

Epoch 00065: val_loss did not improve from 2.19824
Epoch 66/100
56570/56570 - 43s - loss: 1.6746 - accuracy: 0.4237 - val_loss: 2.4219 - val_accuracy: 0.2701

Epoch 00066: val_loss did not improve from 2.19824
Epoch 67/100
56570/56570 - 45s - loss: 1.6752 - accuracy: 0.4239 - val_loss: 2.3798 - val_accuracy: 0.2792

Epoch 00067: val_loss did not improve from 2.19824
Epoch 68/100
56570/56570 - 42s - loss: 1.6758 - accuracy: 0.4236 - val_loss: 2.3871 - val_accuracy: 0.2768

Epoch 00068: val_loss did not improve from 2.19824
Epoch 69/100
56570/56570 - 43s - loss: 1.6761 - accuracy: 0.4232 - val_loss: 2.3608 - val_accuracy: 0.2796

Epoch 00069: val_loss did not improve from 2.19824
Epoch 70/100
56570/56570 - 43s - loss: 1.6770 - accuracy: 0.4242 - val_loss: 2.3946 - val_accuracy: 0.2779

Epoch 00070: val_loss did not improve from 2.19824
Epoch 71/100
56570/56570 - 43s - loss: 1.6769 - accuracy: 0.4232 - val_loss: 2.3129 - val_accuracy: 0.2773

Epoch 00071: val_loss did not improve from 2.19824
Epoch 72/100
56570/56570 - 42s - loss: 1.6781 - accuracy: 0.4227 - val_loss: 2.3792 - val_accuracy: 0.2699

Epoch 00072: val_loss did not improve from 2.19824
Epoch 73/100
56570/56570 - 36s - loss: 1.6780 - accuracy: 0.4233 - val_loss: 2.3535 - val_accuracy: 0.2840

Epoch 00073: val_loss did not improve from 2.19824
Epoch 74/100
56570/56570 - 36s - loss: 1.6795 - accuracy: 0.4237 - val_loss: 2.3798 - val_accuracy: 0.2753

Epoch 00074: val_loss did not improve from 2.19824
Epoch 75/100
56570/56570 - 36s - loss: 1.6803 - accuracy: 0.4223 - val_loss: 2.4732 - val_accuracy: 0.2729

Epoch 00075: val_loss did not improve from 2.19824
Epoch 76/100
56570/56570 - 36s - loss: 1.6797 - accuracy: 0.4222 - val_loss: 2.3370 - val_accuracy: 0.2806

Epoch 00076: val_loss did not improve from 2.19824
Epoch 77/100
56570/56570 - 36s - loss: 1.6800 - accuracy: 0.4231 - val_loss: 2.3675 - val_accuracy: 0.2703

Epoch 00077: val_loss did not improve from 2.19824
Epoch 78/100
56570/56570 - 36s - loss: 1.6796 - accuracy: 0.4230 - val_loss: 2.3879 - val_accuracy: 0.2729

Epoch 00078: val_loss did not improve from 2.19824
Epoch 79/100
56570/56570 - 37s - loss: 1.6811 - accuracy: 0.4220 - val_loss: 2.4264 - val_accuracy: 0.2800

Epoch 00079: val_loss did not improve from 2.19824
Epoch 80/100
56570/56570 - 36s - loss: 1.6807 - accuracy: 0.4229 - val_loss: 2.2968 - val_accuracy: 0.2794

Epoch 00080: val_loss did not improve from 2.19824
Epoch 81/100
56570/56570 - 36s - loss: 1.6807 - accuracy: 0.4221 - val_loss: 2.2980 - val_accuracy: 0.2740

Epoch 00081: val_loss did not improve from 2.19824
Epoch 82/100
56570/56570 - 36s - loss: 1.6818 - accuracy: 0.4223 - val_loss: 2.3818 - val_accuracy: 0.2673

Epoch 00082: val_loss did not improve from 2.19824
Epoch 83/100
56570/56570 - 36s - loss: 1.6824 - accuracy: 0.4224 - val_loss: 2.3418 - val_accuracy: 0.2811

Epoch 00083: val_loss did not improve from 2.19824
Epoch 84/100
56570/56570 - 36s - loss: 1.6829 - accuracy: 0.4217 - val_loss: 2.2972 - val_accuracy: 0.2760

Epoch 00084: val_loss did not improve from 2.19824
Epoch 85/100
56570/56570 - 36s - loss: 1.6827 - accuracy: 0.4221 - val_loss: 2.3724 - val_accuracy: 0.2695

Epoch 00085: val_loss did not improve from 2.19824
Epoch 86/100
56570/56570 - 37s - loss: 1.6829 - accuracy: 0.4214 - val_loss: 2.3362 - val_accuracy: 0.2843

Epoch 00086: val_loss did not improve from 2.19824
Epoch 87/100
56570/56570 - 36s - loss: 1.6836 - accuracy: 0.4218 - val_loss: 2.3642 - val_accuracy: 0.2772

Epoch 00087: val_loss did not improve from 2.19824
Epoch 88/100
56570/56570 - 36s - loss: 1.6829 - accuracy: 0.4217 - val_loss: 2.3681 - val_accuracy: 0.2792

Epoch 00088: val_loss did not improve from 2.19824
Epoch 89/100
56570/56570 - 36s - loss: 1.6850 - accuracy: 0.4210 - val_loss: 2.3728 - val_accuracy: 0.2637

Epoch 00089: val_loss did not improve from 2.19824
Epoch 90/100
56570/56570 - 36s - loss: 1.6857 - accuracy: 0.4211 - val_loss: 2.3135 - val_accuracy: 0.2867

Epoch 00090: val_loss did not improve from 2.19824
Epoch 91/100
56570/56570 - 36s - loss: 1.6842 - accuracy: 0.4209 - val_loss: 2.3417 - val_accuracy: 0.2744

Epoch 00091: val_loss did not improve from 2.19824
Epoch 92/100
56570/56570 - 36s - loss: 1.6841 - accuracy: 0.4215 - val_loss: 2.2663 - val_accuracy: 0.2700

Epoch 00092: val_loss did not improve from 2.19824
Epoch 93/100
56570/56570 - 36s - loss: 1.6863 - accuracy: 0.4200 - val_loss: 2.4190 - val_accuracy: 0.2767

Epoch 00093: val_loss did not improve from 2.19824
Epoch 94/100
56570/56570 - 36s - loss: 1.6846 - accuracy: 0.4216 - val_loss: 2.3887 - val_accuracy: 0.2819

Epoch 00094: val_loss did not improve from 2.19824
Epoch 95/100
56570/56570 - 36s - loss: 1.6848 - accuracy: 0.4221 - val_loss: 2.3680 - val_accuracy: 0.2588

Epoch 00095: val_loss did not improve from 2.19824
Epoch 96/100
56570/56570 - 36s - loss: 1.6844 - accuracy: 0.4210 - val_loss: 2.3230 - val_accuracy: 0.2731

Epoch 00096: val_loss did not improve from 2.19824
Epoch 97/100
56570/56570 - 36s - loss: 1.6860 - accuracy: 0.4212 - val_loss: 2.3573 - val_accuracy: 0.2779

Epoch 00097: val_loss did not improve from 2.19824
Epoch 98/100
56570/56570 - 36s - loss: 1.6859 - accuracy: 0.4207 - val_loss: 2.3509 - val_accuracy: 0.2759

Epoch 00098: val_loss did not improve from 2.19824
Epoch 99/100
56570/56570 - 36s - loss: 1.6855 - accuracy: 0.4219 - val_loss: 2.4879 - val_accuracy: 0.2621

Epoch 00099: val_loss did not improve from 2.19824
Epoch 100/100
56570/56570 - 36s - loss: 1.6853 - accuracy: 0.4209 - val_loss: 2.3502 - val_accuracy: 0.2804

Epoch 00100: val_loss did not improve from 2.19824
