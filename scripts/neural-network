#!/usr/bin/env python3
from sea_ice_rs.install import install

install()

import sys
import yaml
import argparse
import pandas
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score


def process_data(data_file, data_config=None):
    dataframe = pandas.read_csv(data_file, header=0)
    # print(dataframe['label'].value_counts())

    if data_config:
        stream = open(data_config, "r")
        config_dict = yaml.safe_load(stream)

        if "labels" in config_dict.keys():
            try:
                for key, value in config_dict["labels"].items():
                    for i in value:
                        dataframe["label"].replace({i: key}, inplace=True)
            except KeyError:
                print("Error in configuration format", file=sys.stderr)
                sys.exit(1)

        if "features" in config_dict.keys():
            try:
                dataframe.drop(
                    dataframe.columns.difference(config_dict["features"] + ["label"]),
                    1,
                    inplace=True,
                )
            except KeyError:
                print("Error in configuration format", file=sys.stderr)
                sys.exit(1)

    print(f"Features: {[col for col in dataframe.columns]}", file=sys.stdout)
    dataset = dataframe.values
    X = dataset[:, 1:].astype(float)
    Y = dataset[:, 0]
    encoder = LabelEncoder()
    encoder.fit(Y)
    encoded_Y = encoder.transform(Y)

    return X, encoded_Y, encoder.classes_


def main(args):
    X_tr, Y_tr, _ = process_data(args.train_data, args.data_config)

    model = Sequential()

    input_layer_size = X_tr.shape[1]
    output_layer_size = len(np.unique(Y_tr))

    if args.hidden_size == None:
        hidden_layer_size = ((input_layer_size + output_layer_size) * 2) // 3
    else:
        hidden_layer_size = args.hidden_size

    if hidden_layer_size < 2:
        hidden_layer_size = 2

    kfold = StratifiedKFold(n_splits=5, shuffle=False)
    for train, validation in kfold.split(X_tr, Y_tr):
        one_hot_Y_tr = np_utils.to_categorical(Y_tr[train])
        one_hot_Y_val = np_utils.to_categorical(Y_tr[validation])

        model.add(
            Dense(hidden_layer_size, input_dim=input_layer_size, activation="relu")
        )
        model.add(Dense(output_layer_size, activation="softmax"))

        model.compile(
            loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"]
        )

        model.fit(
            x=X_tr[train],
            y=one_hot_Y_tr,
            epochs=args.epochs,
            batch_size=5,
            verbose=1,
            validation_data=(X_tr[validation], one_hot_Y_val),
        )

    X_te, Y_te, classes = process_data(args.test_data, args.data_config)

    y_pred = np.argmax(model.predict(x=X_te, batch_size=5, verbose=1), axis=1)

    print(f"Test accuracy: {accuracy_score(Y_te, y_pred)}", file=sys.stdout)

    np.set_printoptions(threshold=np.inf, linewidth=np.inf, precision=1, suppress=True)
    print(np.asarray([classes]))
    cm = confusion_matrix(Y_te, y_pred, labels=np.unique(Y_te), normalize="true")

    print(cm * 100, file=sys.stdout)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("--train-data", type=str, help="CSV file containing train data")
    parser.add_argument("--test-data", type=str, help="CSV file containing test data")
    parser.add_argument(
        "--data-config",
        type=str,
        help="YAML file containing the configuration for label/feature modification",
    )
    parser.add_argument(
        "--epochs", type=int, help="Number of iterations for training", default=100
    )
    parser.add_argument("--hidden-size", type=int, help="Size of the hidden layer")

    args = parser.parse_args()
    main(args)
